{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a14b1f-f0d4-4d84-a555-2a393b40b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from scipy.sparse import issparse\n",
    "import anndata as adt\n",
    "import celltypist\n",
    "from celltypist import models\n",
    "import scvi\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5a5cd0-3d54-4488-ae4e-341c657493cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install celltypist scvi-tools hyperopt ray[tune] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d57b3cf-d469-4ddb-a5e3-6439ad497059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --user scikit-misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6461b38c-b355-48aa-b6b8-c39e29f990b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adult_COVID19_PBMC.pkl',\n",
       " 'Adult_CynomolgusMacaque_Hippocampus.pkl',\n",
       " 'Adult_Human_MTG.pkl',\n",
       " 'Adult_Human_PancreaticIslet.pkl',\n",
       " 'Adult_Human_PrefrontalCortex.pkl',\n",
       " 'Adult_Human_Skin.pkl',\n",
       " 'Adult_Human_Vascular.pkl',\n",
       " 'Adult_Mouse_Gut.pkl',\n",
       " 'Adult_Mouse_OlfactoryBulb.pkl',\n",
       " 'Adult_Pig_Hippocampus.pkl',\n",
       " 'Adult_RhesusMacaque_Hippocampus.pkl',\n",
       " 'Autopsy_COVID19_Lung.pkl',\n",
       " 'Cells_Adult_Breast.pkl',\n",
       " 'Cells_Fetal_Lung.pkl',\n",
       " 'Cells_Human_Tonsil.pkl',\n",
       " 'Cells_Intestinal_Tract.pkl',\n",
       " 'Cells_Lung_Airway.pkl',\n",
       " 'COVID19_HumanChallenge_Blood.pkl',\n",
       " 'COVID19_Immune_Landscape.pkl',\n",
       " 'Developing_Human_Brain.pkl',\n",
       " 'Developing_Human_Gonads.pkl',\n",
       " 'Developing_Human_Hippocampus.pkl',\n",
       " 'Developing_Human_Organs.pkl',\n",
       " 'Developing_Human_Thymus.pkl',\n",
       " 'Developing_Mouse_Brain.pkl',\n",
       " 'Developing_Mouse_Hippocampus.pkl',\n",
       " 'Fetal_Human_AdrenalGlands.pkl',\n",
       " 'Fetal_Human_Pancreas.pkl',\n",
       " 'Fetal_Human_Pituitary.pkl',\n",
       " 'Fetal_Human_Retina.pkl',\n",
       " 'Fetal_Human_Skin.pkl',\n",
       " 'Healthy_Adult_Heart.pkl',\n",
       " 'Healthy_COVID19_PBMC.pkl',\n",
       " 'Healthy_Human_Liver.pkl',\n",
       " 'Healthy_Mouse_Liver.pkl',\n",
       " 'Human_AdultAged_Hippocampus.pkl',\n",
       " 'Human_Colorectal_Cancer.pkl',\n",
       " 'Human_Developmental_Retina.pkl',\n",
       " 'Human_Embryonic_YolkSac.pkl',\n",
       " 'Human_Endometrium_Atlas.pkl',\n",
       " 'Human_IPF_Lung.pkl',\n",
       " 'Human_Longitudinal_Hippocampus.pkl',\n",
       " 'Human_Lung_Atlas.pkl',\n",
       " 'Human_PF_Lung.pkl',\n",
       " 'Human_Placenta_Decidua.pkl',\n",
       " 'Immune_All_High.pkl',\n",
       " 'Immune_All_Low.pkl',\n",
       " 'Lethal_COVID19_Lung.pkl',\n",
       " 'Mouse_Dentate_Gyrus.pkl',\n",
       " 'Mouse_Isocortex_Hippocampus.pkl',\n",
       " 'Mouse_Postnatal_DentateGyrus.pkl',\n",
       " 'Mouse_Whole_Brain.pkl',\n",
       " 'Nuclei_Lung_Airway.pkl',\n",
       " 'Pan_Fetal_Human.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5315f9f1-8e15-4cff-9876-94768791f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15c8c10-8954-48ed-8b5b-ab2cb21e2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_folder_processed_data = 'G:\\Data processing pipeline 0.1 Yohan\\scRNA\\Output\\processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b9cba4-aced-4d38-aa3c-0e9ae1834381",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = [sc.read_h5ad(path_dir_folder_processed_data + '/' + x) for x in os.listdir(path_dir_folder_processed_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb959a5-4086-405f-8694-78c601862809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 7142 × 18087\n",
       "    obs: 'Sample', 'dpi', 'Id', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb', 'doublet_score_scDbFinder', 'doublet_class_scDbFinder', 'doublet_dbd', 'doublet_score_dbd'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'\n",
       "    uns: 'cells_removed', 'doublets_removed_dbd'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20fc45e-0880-469c-96fe-351421668de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i used models in celltypist :Human_Lung_Atlas & Cells_Lung_Airway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7cf2c-3523-4ed5-aa3c-14c24f71940d",
   "metadata": {},
   "source": [
    "# Query dataset preparation and model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe593c-4bde-4abf-925a-bd4d0f026012",
   "metadata": {},
   "source": [
    "## Preprocessing query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b70319-b510-4946-86f7-f10dd8374f2b",
   "metadata": {},
   "source": [
    "#### Selection normal cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24e8b7a-32b0-4a70-883a-39a0e3ac5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = \"G:/Data processing pipeline 0.1 Yohan/scRNA/Gene ref data/dataset_annot_scRNA_raw.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594956a3-55e4-4fba-a299-bad7337c4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = sc.read_h5ad(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3698d5b6-15f0-4672-bb6d-b0fab5ee5f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disease\n",
       "normal                                   1305099\n",
       "COVID-19                                  341761\n",
       "pulmonary fibrosis                        268932\n",
       "interstitial lung disease                  68456\n",
       "chronic obstructive pulmonary disease      67943\n",
       "lung adenocarcinoma                        62807\n",
       "pneumonia                                  31923\n",
       "chronic rhinitis                           29137\n",
       "lung large cell carcinoma                  21167\n",
       "squamous cell lung carcinoma               20631\n",
       "cystic fibrosis                            17590\n",
       "lymphangioleiomyomatosis                   12374\n",
       "pleomorphic carcinoma                      10765\n",
       "hypersensitivity pneumonitis               10379\n",
       "non-specific interstitial pneumonia         8597\n",
       "pulmonary sarcoidosis                       4886\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.obs['disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4daa07cb-8495-4932-97d3-3059597f5a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suspension_type</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>is_primary_data</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>cell_type_ontology_term_id</th>\n",
       "      <th>development_stage_ontology_term_id</th>\n",
       "      <th>disease_ontology_term_id</th>\n",
       "      <th>self_reported_ethnicity_ontology_term_id</th>\n",
       "      <th>tissue_ontology_term_id</th>\n",
       "      <th>organism_ontology_term_id</th>\n",
       "      <th>...</th>\n",
       "      <th>tissue_type</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>assay</th>\n",
       "      <th>disease</th>\n",
       "      <th>organism</th>\n",
       "      <th>sex</th>\n",
       "      <th>tissue</th>\n",
       "      <th>self_reported_ethnicity</th>\n",
       "      <th>development_stage</th>\n",
       "      <th>observation_joinid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CGATGTAAGTTACGGG_SC10</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>True</td>\n",
       "      <td>EFO:0009899</td>\n",
       "      <td>CL:0000583</td>\n",
       "      <td>HsapDv:0000149</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>HANCESTRO:0008</td>\n",
       "      <td>UBERON:0008946</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>alveolar macrophage</td>\n",
       "      <td>10x 3' v2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung parenchyma</td>\n",
       "      <td>Asian</td>\n",
       "      <td>55-year-old stage</td>\n",
       "      <td>LL;0n*@mx8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc05p_CATGCCTGTGTGCCTG_carraro_csmc</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>True</td>\n",
       "      <td>EFO:0009899</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>UBERON:0002048</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10x 3' v2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>unknown</td>\n",
       "      <td>lung</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>)rNf~Q0&amp;BX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTCTACCAAGGTTCT_HD68</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>True</td>\n",
       "      <td>EFO:0011025</td>\n",
       "      <td>CL:0002144</td>\n",
       "      <td>HsapDv:0000135</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>HANCESTRO:0005</td>\n",
       "      <td>UBERON:0008946</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>capillary endothelial cell</td>\n",
       "      <td>10x 5' v1</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung parenchyma</td>\n",
       "      <td>European</td>\n",
       "      <td>41-year-old stage</td>\n",
       "      <td>5%kv|ie@!5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3</th>\n",
       "      <td>nucleus</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>False</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>CL:4028004</td>\n",
       "      <td>HsapDv:0000262</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>UBERON:0002048</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>alveolar type 1 fibroblast cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung</td>\n",
       "      <td>unknown</td>\n",
       "      <td>newborn stage (0-28 days)</td>\n",
       "      <td>Jq?*-$kHDp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_2_TGCTGCTAGCTCCTCT</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>False</td>\n",
       "      <td>EFO:0009899</td>\n",
       "      <td>CL:0000583</td>\n",
       "      <td>HsapDv:0000169</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>HANCESTRO:0005</td>\n",
       "      <td>UBERON:0008946</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>alveolar macrophage</td>\n",
       "      <td>10x 3' v2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung parenchyma</td>\n",
       "      <td>European</td>\n",
       "      <td>75-year-old stage</td>\n",
       "      <td>Vf*$A^fe9?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3_4_GCTTGAACACGACGAA</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>False</td>\n",
       "      <td>EFO:0009899</td>\n",
       "      <td>CL:0009089</td>\n",
       "      <td>HsapDv:0000145</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>UBERON:0001005</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>lung pericyte</td>\n",
       "      <td>10x 3' v2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>respiratory airway</td>\n",
       "      <td>unknown</td>\n",
       "      <td>51-year-old stage</td>\n",
       "      <td>=%nVC9Pi6~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGTGGATCGTTCCTG_5-PX5-sub_mould</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>True</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>CL:0000583</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>UBERON:0002048</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>alveolar macrophage</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>unknown</td>\n",
       "      <td>lung</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1Y~Wo08=%L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCAGGATCAAGACGTG_F02526</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>True</td>\n",
       "      <td>EFO:0011025</td>\n",
       "      <td>CL:0002145</td>\n",
       "      <td>HsapDv:0000149</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>HANCESTRO:0010</td>\n",
       "      <td>UBERON:0008946</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>ciliated columnar cell of tracheobronchial tree</td>\n",
       "      <td>10x 5' v1</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung parenchyma</td>\n",
       "      <td>African</td>\n",
       "      <td>55-year-old stage</td>\n",
       "      <td>APnAX3m%#T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>False</td>\n",
       "      <td>EFO:0011025</td>\n",
       "      <td>CL:0000583</td>\n",
       "      <td>HsapDv:0000158</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>HANCESTRO:0005</td>\n",
       "      <td>UBERON:0002048</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>alveolar macrophage</td>\n",
       "      <td>10x 5' v1</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung</td>\n",
       "      <td>European</td>\n",
       "      <td>64-year-old stage</td>\n",
       "      <td>5~yXPx7fAJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>022C-b_GGATGTTTCCAAGTAC_adams</th>\n",
       "      <td>cell</td>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>True</td>\n",
       "      <td>EFO:0009899</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>UBERON:0002048</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10x 3' v2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>unknown</td>\n",
       "      <td>lung</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>tC2CvbkoUD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1305099 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            suspension_type  \\\n",
       "CGATGTAAGTTACGGG_SC10                                  cell   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                    cell   \n",
       "ATTCTACCAAGGTTCT_HD68                                  cell   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3           nucleus   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                  cell   \n",
       "...                                                     ...   \n",
       "P3_4_GCTTGAACACGACGAA                                  cell   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                       cell   \n",
       "TCAGGATCAAGACGTG_F02526                                cell   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl            cell   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                          cell   \n",
       "\n",
       "                                                                                      donor_id  \\\n",
       "CGATGTAAGTTACGGG_SC10                        homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc          homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "ATTCTACCAAGGTTCT_HD68                        homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3    homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "P1_2_TGCTGCTAGCTCCTCT                        homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "...                                                                                        ...   \n",
       "P3_4_GCTTGAACACGACGAA                        homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould             homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "TCAGGATCAAGACGTG_F02526                      homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl  homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "\n",
       "                                             is_primary_data  \\\n",
       "CGATGTAAGTTACGGG_SC10                                   True   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                     True   \n",
       "ATTCTACCAAGGTTCT_HD68                                   True   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3              False   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                  False   \n",
       "...                                                      ...   \n",
       "P3_4_GCTTGAACACGACGAA                                  False   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                        True   \n",
       "TCAGGATCAAGACGTG_F02526                                 True   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl            False   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                           True   \n",
       "\n",
       "                                            assay_ontology_term_id  \\\n",
       "CGATGTAAGTTACGGG_SC10                                  EFO:0009899   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                    EFO:0009899   \n",
       "ATTCTACCAAGGTTCT_HD68                                  EFO:0011025   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3              EFO:0009922   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                  EFO:0009899   \n",
       "...                                                            ...   \n",
       "P3_4_GCTTGAACACGACGAA                                  EFO:0009899   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                       EFO:0009922   \n",
       "TCAGGATCAAGACGTG_F02526                                EFO:0011025   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl            EFO:0011025   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                          EFO:0009899   \n",
       "\n",
       "                                            cell_type_ontology_term_id  \\\n",
       "CGATGTAAGTTACGGG_SC10                                       CL:0000583   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                            unknown   \n",
       "ATTCTACCAAGGTTCT_HD68                                       CL:0002144   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3                   CL:4028004   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                       CL:0000583   \n",
       "...                                                                ...   \n",
       "P3_4_GCTTGAACACGACGAA                                       CL:0009089   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                            CL:0000583   \n",
       "TCAGGATCAAGACGTG_F02526                                     CL:0002145   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                 CL:0000583   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                                  unknown   \n",
       "\n",
       "                                            development_stage_ontology_term_id  \\\n",
       "CGATGTAAGTTACGGG_SC10                                           HsapDv:0000149   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                                    unknown   \n",
       "ATTCTACCAAGGTTCT_HD68                                           HsapDv:0000135   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3                       HsapDv:0000262   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                           HsapDv:0000169   \n",
       "...                                                                        ...   \n",
       "P3_4_GCTTGAACACGACGAA                                           HsapDv:0000145   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                                       unknown   \n",
       "TCAGGATCAAGACGTG_F02526                                         HsapDv:0000149   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                     HsapDv:0000158   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                                          unknown   \n",
       "\n",
       "                                            disease_ontology_term_id  \\\n",
       "CGATGTAAGTTACGGG_SC10                                   PATO:0000461   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                     PATO:0000461   \n",
       "ATTCTACCAAGGTTCT_HD68                                   PATO:0000461   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3               PATO:0000461   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                   PATO:0000461   \n",
       "...                                                              ...   \n",
       "P3_4_GCTTGAACACGACGAA                                   PATO:0000461   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                        PATO:0000461   \n",
       "TCAGGATCAAGACGTG_F02526                                 PATO:0000461   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl             PATO:0000461   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                           PATO:0000461   \n",
       "\n",
       "                                            self_reported_ethnicity_ontology_term_id  \\\n",
       "CGATGTAAGTTACGGG_SC10                                                 HANCESTRO:0008   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                                          unknown   \n",
       "ATTCTACCAAGGTTCT_HD68                                                 HANCESTRO:0005   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3                                    unknown   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                                 HANCESTRO:0005   \n",
       "...                                                                              ...   \n",
       "P3_4_GCTTGAACACGACGAA                                                        unknown   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                                             unknown   \n",
       "TCAGGATCAAGACGTG_F02526                                               HANCESTRO:0010   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                           HANCESTRO:0005   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                                                unknown   \n",
       "\n",
       "                                            tissue_ontology_term_id  \\\n",
       "CGATGTAAGTTACGGG_SC10                                UBERON:0008946   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                  UBERON:0002048   \n",
       "ATTCTACCAAGGTTCT_HD68                                UBERON:0008946   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3            UBERON:0002048   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                UBERON:0008946   \n",
       "...                                                             ...   \n",
       "P3_4_GCTTGAACACGACGAA                                UBERON:0001005   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                     UBERON:0002048   \n",
       "TCAGGATCAAGACGTG_F02526                              UBERON:0008946   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl          UBERON:0002048   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                        UBERON:0002048   \n",
       "\n",
       "                                            organism_ontology_term_id  ...  \\\n",
       "CGATGTAAGTTACGGG_SC10                                  NCBITaxon:9606  ...   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                    NCBITaxon:9606  ...   \n",
       "ATTCTACCAAGGTTCT_HD68                                  NCBITaxon:9606  ...   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3              NCBITaxon:9606  ...   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                  NCBITaxon:9606  ...   \n",
       "...                                                               ...  ...   \n",
       "P3_4_GCTTGAACACGACGAA                                  NCBITaxon:9606  ...   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                       NCBITaxon:9606  ...   \n",
       "TCAGGATCAAGACGTG_F02526                                NCBITaxon:9606  ...   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl            NCBITaxon:9606  ...   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                          NCBITaxon:9606  ...   \n",
       "\n",
       "                                            tissue_type  \\\n",
       "CGATGTAAGTTACGGG_SC10                            tissue   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc              tissue   \n",
       "ATTCTACCAAGGTTCT_HD68                            tissue   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3        tissue   \n",
       "P1_2_TGCTGCTAGCTCCTCT                            tissue   \n",
       "...                                                 ...   \n",
       "P3_4_GCTTGAACACGACGAA                            tissue   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                 tissue   \n",
       "TCAGGATCAAGACGTG_F02526                          tissue   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl      tissue   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                    tissue   \n",
       "\n",
       "                                                                                   cell_type  \\\n",
       "CGATGTAAGTTACGGG_SC10                                                    alveolar macrophage   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                                                  unknown   \n",
       "ATTCTACCAAGGTTCT_HD68                                             capillary endothelial cell   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3                    alveolar type 1 fibroblast cell   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                                    alveolar macrophage   \n",
       "...                                                                                      ...   \n",
       "P3_4_GCTTGAACACGACGAA                                                          lung pericyte   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                                         alveolar macrophage   \n",
       "TCAGGATCAAGACGTG_F02526                      ciliated columnar cell of tracheobronchial tree   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                              alveolar macrophage   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                                                        unknown   \n",
       "\n",
       "                                                 assay  disease      organism  \\\n",
       "CGATGTAAGTTACGGG_SC10                        10x 3' v2   normal  Homo sapiens   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc          10x 3' v2   normal  Homo sapiens   \n",
       "ATTCTACCAAGGTTCT_HD68                        10x 5' v1   normal  Homo sapiens   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3    10x 3' v3   normal  Homo sapiens   \n",
       "P1_2_TGCTGCTAGCTCCTCT                        10x 3' v2   normal  Homo sapiens   \n",
       "...                                                ...      ...           ...   \n",
       "P3_4_GCTTGAACACGACGAA                        10x 3' v2   normal  Homo sapiens   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould             10x 3' v3   normal  Homo sapiens   \n",
       "TCAGGATCAAGACGTG_F02526                      10x 5' v1   normal  Homo sapiens   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl  10x 5' v1   normal  Homo sapiens   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                10x 3' v2   normal  Homo sapiens   \n",
       "\n",
       "                                                 sex              tissue  \\\n",
       "CGATGTAAGTTACGGG_SC10                           male     lung parenchyma   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc          unknown                lung   \n",
       "ATTCTACCAAGGTTCT_HD68                           male     lung parenchyma   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3       male                lung   \n",
       "P1_2_TGCTGCTAGCTCCTCT                           male     lung parenchyma   \n",
       "...                                              ...                 ...   \n",
       "P3_4_GCTTGAACACGACGAA                         female  respiratory airway   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould             unknown                lung   \n",
       "TCAGGATCAAGACGTG_F02526                         male     lung parenchyma   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl     male                lung   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                unknown                lung   \n",
       "\n",
       "                                            self_reported_ethnicity  \\\n",
       "CGATGTAAGTTACGGG_SC10                                         Asian   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                         unknown   \n",
       "ATTCTACCAAGGTTCT_HD68                                      European   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3                   unknown   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                      European   \n",
       "...                                                             ...   \n",
       "P3_4_GCTTGAACACGACGAA                                       unknown   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                            unknown   \n",
       "TCAGGATCAAGACGTG_F02526                                     African   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                European   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                               unknown   \n",
       "\n",
       "                                                     development_stage  \\\n",
       "CGATGTAAGTTACGGG_SC10                                55-year-old stage   \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                            unknown   \n",
       "ATTCTACCAAGGTTCT_HD68                                41-year-old stage   \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3    newborn stage (0-28 days)   \n",
       "P1_2_TGCTGCTAGCTCCTCT                                75-year-old stage   \n",
       "...                                                                ...   \n",
       "P3_4_GCTTGAACACGACGAA                                51-year-old stage   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                               unknown   \n",
       "TCAGGATCAAGACGTG_F02526                              55-year-old stage   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl          64-year-old stage   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                                  unknown   \n",
       "\n",
       "                                            observation_joinid  \n",
       "CGATGTAAGTTACGGG_SC10                               LL;0n*@mx8  \n",
       "cc05p_CATGCCTGTGTGCCTG_carraro_csmc                 )rNf~Q0&BX  \n",
       "ATTCTACCAAGGTTCT_HD68                               5%kv|ie@!5  \n",
       "D062_TGACCCTTCAAACCCA-sub_wang_sub_batch3           Jq?*-$kHDp  \n",
       "P1_2_TGCTGCTAGCTCCTCT                               Vf*$A^fe9?  \n",
       "...                                                        ...  \n",
       "P3_4_GCTTGAACACGACGAA                               =%nVC9Pi6~  \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                    1Y~Wo08=%L  \n",
       "TCAGGATCAAGACGTG_F02526                             APnAX3m%#T  \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl         5~yXPx7fAJ  \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                       tC2CvbkoUD  \n",
       "\n",
       "[1305099 rows x 70 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[query.obs.disease == 'normal'].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a699a3-92b0-43b0-881f-df56cb374002",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query[query.obs.disease == 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ca5da1-2e05-4e93-8ec7-18679ff489d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.write('G:/Data processing pipeline 0.1 Yohan/scRNA/Gene ref data/query_healthy_cells.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b9b86-d02d-448a-af0b-a2c2a9856f65",
   "metadata": {},
   "source": [
    "#### Verification raw counts & keep only raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae09354-d9de-4727-8dd0-9e4226560565",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = sc.read_h5ad('G:/Data processing pipeline 0.1 Yohan/scRNA/Gene ref data/query_healthy_cells.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67495518-ce07-4ec5-a359-e94fed98c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmve(query):\n",
    "\n",
    "    remove = [\n",
    "        'is_primary_data', 'assay_ontology_term_id',\n",
    "        'cell_type_ontology_term_id', 'development_stage_ontology_term_id', \n",
    "        'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id',\n",
    "        'tissue_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', \n",
    "        'BMI', 'age_or_mean_of_age_range', 'age_range', 'cause_of_death', 'fresh_or_frozen',\n",
    "         'lung_condition', \n",
    "        'mixed_ancestry', \n",
    "        'smoking_status',  'tissue_dissociation_protocol', 'tissue_level_2', \n",
    "        'tissue_level_3', 'tissue_sampling_method', 'tissue_type',  'assay',  'organism',\n",
    "        'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid',\n",
    "    \n",
    "        'suspension_type', 'anatomical_region_ccf_score', \n",
    "         'dataset', 'entropy_dataset_leiden_3', 'entropy_original_ann_level_1_leiden_3',\n",
    "        'entropy_original_ann_level_2_clean_leiden_3', 'entropy_original_ann_level_3_clean_leiden_3', \n",
    "        'entropy_subject_ID_leiden_3', 'leiden_1', 'leiden_2', 'leiden_3', 'leiden_4', 'leiden_5', \n",
    "         'original_ann_highest_res', 'original_ann_level_1', \n",
    "        'original_ann_level_2', 'original_ann_level_3', 'original_ann_level_4', 'original_ann_level_5',\n",
    "        'original_ann_nonharmonized', 'reannotation_type', 'reference_genome', 'sample',\n",
    "        'sequencing_platform', 'size_factors', 'subject_type', 'size_factors', 'sample'\n",
    "    ]\n",
    "\n",
    "    query.obs = query.obs[[x for x in query.obs.columns if x not in remove]]\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc154686-5db8-4c07-912f-ddb99d2115b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = rmve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6a8dd6-f294-4467-9592-3a3e05987997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc(adata):\n",
    "    sc.pp.filter_cells(adata, min_genes = 200)\n",
    "    adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "    adata.var[\"ribo\"] = adata.var_names.str.startswith(\"RPS\", \"RPL\")\n",
    "    adata.var[\"hb\"] = adata.var_names.str.startswith(\"^HB[^(P)]\")\n",
    "    sc.pp.calculate_qc_metrics(adata,qc_vars=[\"mt\",\"ribo\",\"hb\"], inplace = True, percent_top = [20], log1p=True)\n",
    "\n",
    "    remove = ['total_counts_mt', 'log1p_total_counts_mt', 'total_counts_ribo',\n",
    "              'log1p_total_counts_ribo','total_counts_hb','log1p_total_counts_hb']\n",
    "\n",
    "    adata.obs = adata.obs[[x for x in adata.obs.columns if x not in remove]]\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95096ff1-422e-4a20-b7ca-83c494a981e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_raw = adt.AnnData(X=query.raw.X, obs=query.obs, var=query.raw.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d1bbf-1155-4e77-991a-c28d322fff93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8730c00d-0acd-49da-9842-e97a3f1d34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_raw = qc(query_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64dde7b8-a46b-474e-ae63-12cea90ed9bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = sns.displot(query_raw.obs[\"total_counts\"], bins=100, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464803d5-389d-4f63-9ac0-b1c29761ab05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1302742 × 56239\n",
       "    obs: 'suspension_type', 'donor_id', 'is_primary_data', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'tissue_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', \"3'_or_5'\", 'BMI', 'age_or_mean_of_age_range', 'age_range', 'anatomical_region_ccf_score', 'ann_coarse_for_GWAS_and_modeling', 'ann_finest_level', 'ann_level_1', 'ann_level_2', 'ann_level_3', 'ann_level_4', 'ann_level_5', 'cause_of_death', 'core_or_extension', 'dataset', 'fresh_or_frozen', 'log10_total_counts', 'lung_condition', 'mixed_ancestry', 'original_ann_level_1', 'original_ann_level_2', 'original_ann_level_3', 'original_ann_level_4', 'original_ann_level_5', 'original_ann_nonharmonized', 'reannotation_type', 'sample', 'scanvi_label', 'sequencing_platform', 'smoking_status', 'study', 'subject_type', 'tissue_coarse_unharmonized', 'tissue_detailed_unharmonized', 'tissue_dissociation_protocol', 'tissue_level_2', 'tissue_level_3', 'tissue_sampling_method', 'total_counts', 'transf_ann_level_1_label', 'transf_ann_level_1_uncert', 'transf_ann_level_2_label', 'transf_ann_level_2_uncert', 'transf_ann_level_3_label', 'transf_ann_level_3_uncert', 'transf_ann_level_4_label', 'transf_ann_level_4_uncert', 'transf_ann_level_5_label', 'transf_ann_level_5_uncert', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb'\n",
       "    var: 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b6c45f-2271-4c8c-bb72-29c0725377ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_raw.write('G:/Data processing pipeline 0.1 Yohan/scRNA/Gene ref data/query_raw_healthy_cells.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920321e-5e4a-4d87-ae6d-a4711e9cdfa4",
   "metadata": {},
   "source": [
    "## Download models celltypist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d96f8c1-a3b7-4f36-9931-9b10483ad240",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_celltypist1 = models.Model.load(model='Human_Lung_Atlas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "125b63fc-4d8b-423e-9cb9-a89ca58a623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TSPAN6', 'FGR', 'CFH', ..., 'LINC00891', 'LL22NC03-N95F10.1',\n",
       "       'RP1-34B20.21'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_celltypist1.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03590b49-0d91-4b47-bc08-fcfaa4830e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_celltypist2 = models.Model.load(model='Cells_Lung_Airway.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ecbee2-d8a8-4998-9598-dd07ccb313ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AT1 ', 'AT2', 'B_memory', 'B_naive', 'B_plasma_IgA',\n",
       "       'B_plasma_IgG', 'B_plasmablast', 'Basal', 'CD4_EM/Effector',\n",
       "       'CD4_TRM', 'CD4_naive/CM', 'CD8_EM', 'CD8_EM/EMRA', 'CD8_TRM',\n",
       "       'CD8_TRM/EM', 'Chondrocyte', 'Ciliated', 'DC_1', 'DC_2',\n",
       "       'DC_activated', 'DC_plasmacytoid', 'Deuterosomal', 'Dividing_AT2',\n",
       "       'Dividing_Basal', 'Endothelia_Lymphatic',\n",
       "       'Endothelia_vascular_Cap_a', 'Endothelia_vascular_Cap_g',\n",
       "       'Endothelia_vascular_arterial_pulmonary',\n",
       "       'Endothelia_vascular_arterial_systemic',\n",
       "       'Endothelia_vascular_venous_pulmonary',\n",
       "       'Endothelia_vascular_venous_systemic', 'Erythrocyte',\n",
       "       'Fibro_adventitial', 'Fibro_alveolar', 'Fibro_immune_recruiting',\n",
       "       'Fibro_myofibroblast', 'Fibro_peribronchial', 'ILC',\n",
       "       'Ionocyte_n_Brush', 'MAIT', 'Macro_AW_CX3CR1', 'Macro_CCL',\n",
       "       'Macro_CHIT1', 'Macro_alveolar', 'Macro_alveolar_metallothioneins',\n",
       "       'Macro_dividing', 'Macro_intermediate', 'Macro_interstitial',\n",
       "       'Macro_intravascular', 'Mast_cell ', 'Megakaryocyte', 'Mesothelia',\n",
       "       'Monocyte_CD14', 'Monocyte_CD16', 'Muscle_pericyte_pulmonary',\n",
       "       'Muscle_pericyte_systemic',\n",
       "       'Muscle_perivascular_immune_recruiting', 'Muscle_smooth_airway',\n",
       "       'Muscle_smooth_arterial_systemic', 'Muscle_smooth_pulmonary',\n",
       "       'NAF_endoneurial', 'NAF_perineurial', 'NKT', 'NK_CD11d',\n",
       "       'NK_CD16hi', 'NK_CD56bright', 'Neuroendocrine', 'SMG_Basal',\n",
       "       'SMG_Duct', 'SMG_Mucous', 'SMG_Serous', 'Schwann_Myelinating',\n",
       "       'Schwann_nonmyelinating', 'Secretory_Club', 'Secretory_Goblet',\n",
       "       'Suprabasal', 'T_reg', 'gdT'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_celltypist2.cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c8d8c-506a-4ff7-a889-362d4afd5249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b19e49b-be3b-4124-8bbc-163ea5cf0cd4",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb0e65-ca8e-4b95-b2f8-91d9b93ad8f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Query HLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31dfeba3-a74d-4ae5-b58c-ea97bb6399d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crashed, i have to segment it but not necessary because used in Human_Lung_Atlas as model(same doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46e7a33b-1050-4edd-b581-0468ceb2326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_type\n",
       "hematopoietic stem cell                               60\n",
       "fibroblast                                           276\n",
       "mesothelial cell                                     230\n",
       "T cell                                               500\n",
       "mast cell                                           6623\n",
       "club cell                                          36023\n",
       "myofibroblast cell                                   716\n",
       "smooth muscle cell                                   556\n",
       "B cell                                              4511\n",
       "serous secreting cell                               1472\n",
       "mucus secreting cell                                 537\n",
       "dendritic cell                                       312\n",
       "stromal cell                                         335\n",
       "alveolar macrophage                                78816\n",
       "acinar cell                                         1274\n",
       "natural killer cell                                16978\n",
       "CD4-positive, alpha-beta T cell                    21285\n",
       "CD8-positive, alpha-beta T cell                    29074\n",
       "plasmacytoid dendritic cell                          552\n",
       "plasma cell                                         1773\n",
       "classical monocyte                                 17695\n",
       "elicited macrophage                                28223\n",
       "non-classical monocyte                              8834\n",
       "conventional dendritic cell                          322\n",
       "pulmonary alveolar type 1 cell                      7937\n",
       "pulmonary alveolar type 2 cell                     62405\n",
       "brush cell of tracheobronchial tree                  165\n",
       "endothelial cell of lymphatic vessel                4595\n",
       "capillary endothelial cell                         23205\n",
       "ciliated columnar cell of tracheobronchial tree    35225\n",
       "CD1c-positive myeloid dendritic cell                9133\n",
       "nasal mucosa goblet cell                           35833\n",
       "vein endothelial cell                              12975\n",
       "epithelial cell of lower respiratory tract          4393\n",
       "respiratory basal cell                             80113\n",
       "ionocyte                                             561\n",
       "multi-ciliated epithelial cell                      5873\n",
       "lung pericyte                                       3032\n",
       "epithelial cell of alveolus of lung                 1440\n",
       "tracheobronchial serous cell                        1417\n",
       "tracheobronchial goblet cell                         968\n",
       "tracheobronchial smooth muscle cell                 2996\n",
       "lung neuroendocrine cell                             159\n",
       "bronchial goblet cell                               1670\n",
       "pulmonary artery endothelial cell                   7391\n",
       "lung macrophage                                     4805\n",
       "bronchus fibroblast of lung                         1573\n",
       "alveolar type 1 fibroblast cell                     5182\n",
       "alveolar adventitial fibroblast                    10321\n",
       "respiratory hillock cell                            4600\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.obs.groupby('cell_type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d7d21f0-1515-44aa-b2c0-9f4d5df098ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(query, min_cells = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9949f11e-4490-40b7-af01-aded323755bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(query, target_sum = 1e4)\n",
    "sc.pp.log1p(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07c8d696-2645-45c8-a618-08b7b501fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query[~query.obs.cell_type.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ec060-629e-4a45-9eae-95e04772a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n"
     ]
    }
   ],
   "source": [
    "ref_model = celltypist.train(query, labels = 'cell_type', n_jobs = 22,\n",
    "                            use_SGD = False,\n",
    "                            feature_selection = True, top_genes = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f0137-d957-4d3e-8b5d-f231510142be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = 'G:\\Data processing pipeline 0.1 Yohan\\scRNA\\Output\\ref_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54aa3e9-358c-4250-a401-9d2ac3ac8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model.write(path_model + '/' + 'ref.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e191e0-b052-4a6c-9982-9e08d0a356cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f207ff-f849-47ae-abd1-2f3fda6fa5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the former part is useless i don't need it and i should erase it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9163de0-8822-42eb-b496-3cb7896385dd",
   "metadata": {},
   "source": [
    "## Download ref models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98d76583-afb0-4322-80fe-a7e1e31957bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref_model = models.Model.load(model=\"ref.pkl\")\n",
    "ref_model_celltypist1 = models.Model.load(model=\"Cells_Lung_Airway.pkl\")\n",
    "ref_model_celltypist2 = models.Model.load(model=\"Human_Lung_Atlas.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ddf6e-c1b6-4fc5-ba57-1fe8116f8bc9",
   "metadata": {},
   "source": [
    "# Prediction cell type using celltypist method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177145d7-72da-41be-a37a-a98de93bc7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cells(adata):\n",
    "    sc.pp.filter_genes(adata, min_cells = 10)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4) #maybe modify it\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    adata.X = adata.X.toarray()\n",
    "\n",
    "    #predictions = celltypist.annotate(adata, model=ref_model, majority_voting=False)\n",
    "    #predictions_adata = predictions.to_adata()\n",
    "    #adata.obs[\"ref_model_label\"] = predictions_adata.obs.loc[adata.obs.index, \"predicted_labels\"]\n",
    "    #adata.obs[\"ref_model_score\"] = predictions_adata.obs.loc[adata.obs.index, \"conf_score\"]\n",
    "\n",
    "    predictions = celltypist.annotate(adata, model=query_celltypist1, majority_voting=False)\n",
    "    predictions_adata = predictions.to_adata()\n",
    "    adata.obs[\"ref_model_celltypist1_label\"] = predictions_adata.obs.loc[adata.obs.index, \"predicted_labels\"]\n",
    "    adata.obs[\"ref_model_celltypist1_score\"] = predictions_adata.obs.loc[adata.obs.index, \"conf_score\"]\n",
    "\n",
    "    predictions = celltypist.annotate(adata, model=query_celltypist2, majority_voting=False)\n",
    "    predictions_adata = predictions.to_adata()\n",
    "    adata.obs[\"ref_model_celltypist2_label\"] = predictions_adata.obs.loc[adata.obs.index, \"predicted_labels\"]\n",
    "    adata.obs[\"ref_model_celltypist2_score\"] = predictions_adata.obs.loc[adata.obs.index, \"conf_score\"]\n",
    "    \n",
    "    return adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49843240-3091-4f2f-bddb-5e03d9f7831a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a16c2a74-8a4d-4052-9995-0fb60548bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 7142 cells and 14213 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3865 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🔬 Input data has 7142 cells and 14213 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 4002 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🔬 Input data has 6007 cells and 13998 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3798 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🔬 Input data has 6007 cells and 13998 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3936 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🔬 Input data has 6753 cells and 14001 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3786 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🔬 Input data has 6753 cells and 14001 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3923 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🔬 Input data has 5398 cells and 13875 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3755 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🔬 Input data has 5398 cells and 13875 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 3898 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    }
   ],
   "source": [
    "predictions = [predict_cells(ad.copy()) for ad in adatas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "089a9320-7b4e-4bf6-bfcf-d0b3cb0d3737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_model_celltypist1_label</th>\n",
       "      <th>ref_model_celltypist1_score</th>\n",
       "      <th>ref_model_celltypist2_label</th>\n",
       "      <th>ref_model_celltypist2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.319114</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.951831</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.824988</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.357202</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.602141</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>AT2</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.987707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.080242</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.998898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.997562</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.996979</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.923008</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ref_model_celltypist1_label  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "...                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                         AT2   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "\n",
       "                                    ref_model_celltypist1_score  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                      0.319114   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                      0.951831   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                      0.824988   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                      0.357202   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                      0.602141   \n",
       "...                                                         ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                     0.055499   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                     0.080242   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                     0.997562   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                     0.996979   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                     0.923008   \n",
       "\n",
       "                                   ref_model_celltypist2_label  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "...                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "\n",
       "                                    ref_model_celltypist2_score  \n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                      0.999951  \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                      0.999886  \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                      0.999993  \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                      0.999483  \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                      0.999654  \n",
       "...                                                         ...  \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                     0.987707  \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                     0.998898  \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                     1.000000  \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                     0.999873  \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                     0.999691  \n",
       "\n",
       "[25300 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.concat(predictions)[['ref_model_celltypist1_label', 'ref_model_celltypist1_score',\n",
    "                                      'ref_model_celltypist2_label', 'ref_model_celltypist2_score']]\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a04ab-2734-4ba7-8179-e65095796e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindexing in order to concatenat correctly the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18c1b613-9df2-437b-8d75-1378ed44c19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_ids</th>\n",
       "      <th>feature_types</th>\n",
       "      <th>genome</th>\n",
       "      <th>mt</th>\n",
       "      <th>ribo</th>\n",
       "      <th>hb</th>\n",
       "      <th>n_cells_by_counts</th>\n",
       "      <th>mean_counts</th>\n",
       "      <th>log1p_mean_counts</th>\n",
       "      <th>pct_dropout_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAMD11</th>\n",
       "      <td>ENSG00000187634</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>99.918159</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOC2L</th>\n",
       "      <td>ENSG00000188976</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5323</td>\n",
       "      <td>0.807675</td>\n",
       "      <td>0.592041</td>\n",
       "      <td>51.595890</td>\n",
       "      <td>8882.0</td>\n",
       "      <td>9.091894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLHL17</th>\n",
       "      <td>ENSG00000187961</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>891</td>\n",
       "      <td>0.088570</td>\n",
       "      <td>0.084865</td>\n",
       "      <td>91.897790</td>\n",
       "      <td>974.0</td>\n",
       "      <td>6.882438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLEKHN1</th>\n",
       "      <td>ENSG00000187583</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2216</td>\n",
       "      <td>0.305174</td>\n",
       "      <td>0.266336</td>\n",
       "      <td>79.849050</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>8.118803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERM1</th>\n",
       "      <td>ENSG00000187642</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>99.463490</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.158883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFP</th>\n",
       "      <td>EGFP</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>237</td>\n",
       "      <td>0.733746</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>97.844867</td>\n",
       "      <td>8069.0</td>\n",
       "      <td>8.995909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REPLI</th>\n",
       "      <td>REPLI</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>392</td>\n",
       "      <td>0.503683</td>\n",
       "      <td>0.407917</td>\n",
       "      <td>96.435391</td>\n",
       "      <td>5539.0</td>\n",
       "      <td>8.619750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLYCO</th>\n",
       "      <td>GLYCO</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>371</td>\n",
       "      <td>0.860144</td>\n",
       "      <td>0.620654</td>\n",
       "      <td>96.626353</td>\n",
       "      <td>9459.0</td>\n",
       "      <td>9.154828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMB</th>\n",
       "      <td>MEMB</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>647</td>\n",
       "      <td>2.885332</td>\n",
       "      <td>1.357208</td>\n",
       "      <td>94.116577</td>\n",
       "      <td>31730.0</td>\n",
       "      <td>10.365049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUCL</th>\n",
       "      <td>NUCL</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>628</td>\n",
       "      <td>3.666091</td>\n",
       "      <td>1.540322</td>\n",
       "      <td>94.289352</td>\n",
       "      <td>40316.0</td>\n",
       "      <td>10.604528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18087 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gene_ids    feature_types  \\\n",
       "SAMD11   ENSG00000187634  Gene Expression   \n",
       "NOC2L    ENSG00000188976  Gene Expression   \n",
       "KLHL17   ENSG00000187961  Gene Expression   \n",
       "PLEKHN1  ENSG00000187583  Gene Expression   \n",
       "PERM1    ENSG00000187642  Gene Expression   \n",
       "...                  ...              ...   \n",
       "EGFP                EGFP  Gene Expression   \n",
       "REPLI              REPLI  Gene Expression   \n",
       "GLYCO              GLYCO  Gene Expression   \n",
       "MEMB                MEMB  Gene Expression   \n",
       "NUCL                NUCL  Gene Expression   \n",
       "\n",
       "                                         genome     mt   ribo     hb  \\\n",
       "SAMD11   refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "NOC2L    refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "KLHL17   refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "PLEKHN1  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "PERM1    refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "...                                         ...    ...    ...    ...   \n",
       "EGFP     refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "REPLI    refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "GLYCO    refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "MEMB     refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "NUCL     refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "\n",
       "         n_cells_by_counts  mean_counts  log1p_mean_counts  \\\n",
       "SAMD11                   9     0.000818           0.000818   \n",
       "NOC2L                 5323     0.807675           0.592041   \n",
       "KLHL17                 891     0.088570           0.084865   \n",
       "PLEKHN1               2216     0.305174           0.266336   \n",
       "PERM1                   59     0.005729           0.005712   \n",
       "...                    ...          ...                ...   \n",
       "EGFP                   237     0.733746           0.550284   \n",
       "REPLI                  392     0.503683           0.407917   \n",
       "GLYCO                  371     0.860144           0.620654   \n",
       "MEMB                   647     2.885332           1.357208   \n",
       "NUCL                   628     3.666091           1.540322   \n",
       "\n",
       "         pct_dropout_by_counts  total_counts  log1p_total_counts  \n",
       "SAMD11               99.918159           9.0            2.302585  \n",
       "NOC2L                51.595890        8882.0            9.091894  \n",
       "KLHL17               91.897790         974.0            6.882438  \n",
       "PLEKHN1              79.849050        3356.0            8.118803  \n",
       "PERM1                99.463490          63.0            4.158883  \n",
       "...                        ...           ...                 ...  \n",
       "EGFP                 97.844867        8069.0            8.995909  \n",
       "REPLI                96.435391        5539.0            8.619750  \n",
       "GLYCO                96.626353        9459.0            9.154828  \n",
       "MEMB                 94.116577       31730.0           10.365049  \n",
       "NUCL                 94.289352       40316.0           10.604528  \n",
       "\n",
       "[18087 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas[0].var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96ba70db-5125-42c1-891c-4254ff9d5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindexing(adata):\n",
    "    \n",
    "    adata.var = adata.var.reset_index()\n",
    "    adata.var = adata.var.rename(columns={'index': 'gene_names'})\n",
    "    adata.var = adata.var.set_index('gene_ids')\n",
    "    adata.var = adata.var.rename_axis(None)\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9937f87-63ec-41d3-a8fc-259473469475",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = [reindexing(ad) for ad in adatas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "306d711e-e957-478b-b305-7f94bb2a4e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_names</th>\n",
       "      <th>feature_types</th>\n",
       "      <th>genome</th>\n",
       "      <th>mt</th>\n",
       "      <th>ribo</th>\n",
       "      <th>hb</th>\n",
       "      <th>n_cells_by_counts</th>\n",
       "      <th>mean_counts</th>\n",
       "      <th>log1p_mean_counts</th>\n",
       "      <th>pct_dropout_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000187634</th>\n",
       "      <td>SAMD11</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>99.952571</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000188976</th>\n",
       "      <td>NOC2L</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4223</td>\n",
       "      <td>0.592961</td>\n",
       "      <td>0.465595</td>\n",
       "      <td>59.941188</td>\n",
       "      <td>6251.0</td>\n",
       "      <td>8.740657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187961</th>\n",
       "      <td>KLHL17</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>719</td>\n",
       "      <td>0.072946</td>\n",
       "      <td>0.070408</td>\n",
       "      <td>93.179662</td>\n",
       "      <td>769.0</td>\n",
       "      <td>6.646390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187583</th>\n",
       "      <td>PLEKHN1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.190571</td>\n",
       "      <td>0.174433</td>\n",
       "      <td>86.719788</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.605890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187642</th>\n",
       "      <td>PERM1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>73</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>99.307532</td>\n",
       "      <td>83.0</td>\n",
       "      <td>4.430817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFP</th>\n",
       "      <td>EGFP</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>99.924113</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.197225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REPLI</th>\n",
       "      <td>REPLI</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>99.990514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLYCO</th>\n",
       "      <td>GLYCO</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>99.943085</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.945910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMB</th>\n",
       "      <td>MEMB</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>99.867198</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUCL</th>\n",
       "      <td>NUCL</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>99.800797</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.091043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18087 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gene_names    feature_types  \\\n",
       "ENSG00000187634     SAMD11  Gene Expression   \n",
       "ENSG00000188976      NOC2L  Gene Expression   \n",
       "ENSG00000187961     KLHL17  Gene Expression   \n",
       "ENSG00000187583    PLEKHN1  Gene Expression   \n",
       "ENSG00000187642      PERM1  Gene Expression   \n",
       "...                    ...              ...   \n",
       "EGFP                  EGFP  Gene Expression   \n",
       "REPLI                REPLI  Gene Expression   \n",
       "GLYCO                GLYCO  Gene Expression   \n",
       "MEMB                  MEMB  Gene Expression   \n",
       "NUCL                  NUCL  Gene Expression   \n",
       "\n",
       "                                                 genome     mt   ribo     hb  \\\n",
       "ENSG00000187634  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000188976  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000187961  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000187583  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000187642  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "...                                                 ...    ...    ...    ...   \n",
       "EGFP             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "REPLI            refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "GLYCO            refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "MEMB             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "NUCL             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "\n",
       "                 n_cells_by_counts  mean_counts  log1p_mean_counts  \\\n",
       "ENSG00000187634                  5     0.000474           0.000474   \n",
       "ENSG00000188976               4223     0.592961           0.465595   \n",
       "ENSG00000187961                719     0.072946           0.070408   \n",
       "ENSG00000187583               1400     0.190571           0.174433   \n",
       "ENSG00000187642                 73     0.007873           0.007842   \n",
       "...                            ...          ...                ...   \n",
       "EGFP                             8     0.000759           0.000759   \n",
       "REPLI                            1     0.000095           0.000095   \n",
       "GLYCO                            6     0.000569           0.000569   \n",
       "MEMB                            14     0.001423           0.001422   \n",
       "NUCL                            21     0.001992           0.001990   \n",
       "\n",
       "                 pct_dropout_by_counts  total_counts  log1p_total_counts  \n",
       "ENSG00000187634              99.952571           5.0            1.791759  \n",
       "ENSG00000188976              59.941188        6251.0            8.740657  \n",
       "ENSG00000187961              93.179662         769.0            6.646390  \n",
       "ENSG00000187583              86.719788        2009.0            7.605890  \n",
       "ENSG00000187642              99.307532          83.0            4.430817  \n",
       "...                                ...           ...                 ...  \n",
       "EGFP                         99.924113           8.0            2.197225  \n",
       "REPLI                        99.990514           1.0            0.693147  \n",
       "GLYCO                        99.943085           6.0            1.945910  \n",
       "MEMB                         99.867198          15.0            2.772589  \n",
       "NUCL                         99.800797          21.0            3.091043  \n",
       "\n",
       "[18087 rows x 12 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas[2].var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a09978c3-b81a-410d-bcd9-2a002af8b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adt.concat(adatas, join=\"outer\", index_unique=\"-\", merge=\"unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4491ec7d-16c4-4224-b742-a7c0c54eb5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_names</th>\n",
       "      <th>feature_types</th>\n",
       "      <th>genome</th>\n",
       "      <th>mt</th>\n",
       "      <th>ribo</th>\n",
       "      <th>hb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000187634</th>\n",
       "      <td>SAMD11</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000188976</th>\n",
       "      <td>NOC2L</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187961</th>\n",
       "      <td>KLHL17</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187583</th>\n",
       "      <td>PLEKHN1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187642</th>\n",
       "      <td>PERM1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFP</th>\n",
       "      <td>EGFP</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REPLI</th>\n",
       "      <td>REPLI</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLYCO</th>\n",
       "      <td>GLYCO</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMB</th>\n",
       "      <td>MEMB</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUCL</th>\n",
       "      <td>NUCL</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18087 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gene_names    feature_types  \\\n",
       "ENSG00000187634     SAMD11  Gene Expression   \n",
       "ENSG00000188976      NOC2L  Gene Expression   \n",
       "ENSG00000187961     KLHL17  Gene Expression   \n",
       "ENSG00000187583    PLEKHN1  Gene Expression   \n",
       "ENSG00000187642      PERM1  Gene Expression   \n",
       "...                    ...              ...   \n",
       "EGFP                  EGFP  Gene Expression   \n",
       "REPLI                REPLI  Gene Expression   \n",
       "GLYCO                GLYCO  Gene Expression   \n",
       "MEMB                  MEMB  Gene Expression   \n",
       "NUCL                  NUCL  Gene Expression   \n",
       "\n",
       "                                                 genome     mt   ribo     hb  \n",
       "ENSG00000187634  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "ENSG00000188976  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "ENSG00000187961  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "ENSG00000187583  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "ENSG00000187642  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "...                                                 ...    ...    ...    ...  \n",
       "EGFP             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "REPLI            refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "GLYCO            refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "MEMB             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "NUCL             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False  \n",
       "\n",
       "[18087 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "342322d1-f446-4b49-a17d-81939dc993c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc(adata):\n",
    "    sc.pp.filter_cells(adata, min_genes = 200)\n",
    "    adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "    adata.var[\"ribo\"] = adata.var_names.str.startswith(\"RPS\", \"RPL\")\n",
    "    adata.var[\"hb\"] = adata.var_names.str.startswith(\"^HB[^(P)]\")\n",
    "    sc.pp.calculate_qc_metrics(adata,qc_vars=[\"mt\",\"ribo\",\"hb\"], inplace = True, percent_top = [20], log1p=True)\n",
    "\n",
    "    remove = ['total_counts_mt', 'log1p_total_counts_mt', 'total_counts_ribo',\n",
    "              'log1p_total_counts_ribo','total_counts_hb','log1p_total_counts_hb']\n",
    "\n",
    "    adata.obs = adata.obs[[x for x in adata.obs.columns if x not in remove]]\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95d326cf-5152-4f16-88a7-5e87d13255e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = qc(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94abc76b-f5e7-42f6-b2ef-925103395c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>dpi</th>\n",
       "      <th>Id</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>log1p_n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "      <th>pct_counts_in_top_20_genes</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>pct_counts_ribo</th>\n",
       "      <th>pct_counts_hb</th>\n",
       "      <th>doublet_score_scDbFinder</th>\n",
       "      <th>doublet_class_scDbFinder</th>\n",
       "      <th>doublet_dbd</th>\n",
       "      <th>doublet_score_dbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4997</td>\n",
       "      <td>4997</td>\n",
       "      <td>8.516793</td>\n",
       "      <td>15760.0</td>\n",
       "      <td>9.665294</td>\n",
       "      <td>16.935279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.467655e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4357</td>\n",
       "      <td>4357</td>\n",
       "      <td>8.379769</td>\n",
       "      <td>14550.0</td>\n",
       "      <td>9.585415</td>\n",
       "      <td>26.054983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.596916e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>6425</td>\n",
       "      <td>6425</td>\n",
       "      <td>8.768108</td>\n",
       "      <td>37675.0</td>\n",
       "      <td>10.536778</td>\n",
       "      <td>39.777040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175868</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.579486e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4802</td>\n",
       "      <td>4802</td>\n",
       "      <td>8.476996</td>\n",
       "      <td>12024.0</td>\n",
       "      <td>9.394743</td>\n",
       "      <td>9.971723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.458157e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4699</td>\n",
       "      <td>4699</td>\n",
       "      <td>8.455318</td>\n",
       "      <td>15655.0</td>\n",
       "      <td>9.658609</td>\n",
       "      <td>23.027787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.945921e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5428</td>\n",
       "      <td>5428</td>\n",
       "      <td>8.599510</td>\n",
       "      <td>17390.0</td>\n",
       "      <td>9.763708</td>\n",
       "      <td>15.043128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.440510e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>6077</td>\n",
       "      <td>6077</td>\n",
       "      <td>8.712431</td>\n",
       "      <td>21812.0</td>\n",
       "      <td>9.990261</td>\n",
       "      <td>18.732808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>singlet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.328824e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5301</td>\n",
       "      <td>5301</td>\n",
       "      <td>8.575839</td>\n",
       "      <td>15610.0</td>\n",
       "      <td>9.655731</td>\n",
       "      <td>11.249199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184157</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.199975e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5857</td>\n",
       "      <td>5857</td>\n",
       "      <td>8.675564</td>\n",
       "      <td>24456.0</td>\n",
       "      <td>10.104671</td>\n",
       "      <td>26.255316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064821</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.128238e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>4998</td>\n",
       "      <td>4998</td>\n",
       "      <td>8.516993</td>\n",
       "      <td>17457.0</td>\n",
       "      <td>9.767553</td>\n",
       "      <td>27.456035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.697339e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25300 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Sample dpi       Id  n_genes  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4997   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4357   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     6425   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4802   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4699   \n",
       "...                                     ...  ..      ...      ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     5428   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     6077   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     5301   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     5857   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     4998   \n",
       "\n",
       "                                      n_genes_by_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                4997   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                4357   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                6425   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                4802   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                4699   \n",
       "...                                                 ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3               5428   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3               6077   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3               5301   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3               5857   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3               4998   \n",
       "\n",
       "                                      log1p_n_genes_by_counts  total_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                  8.516793       15760.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                  8.379769       14550.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                  8.768108       37675.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                  8.476996       12024.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                  8.455318       15655.0   \n",
       "...                                                       ...           ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                 8.599510       17390.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                 8.712431       21812.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                 8.575839       15610.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3                 8.675564       24456.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                 8.516993       17457.0   \n",
       "\n",
       "                                      log1p_total_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0             9.665294   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0             9.585415   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0            10.536778   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0             9.394743   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0             9.658609   \n",
       "...                                                  ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3            9.763708   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3            9.990261   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3            9.655731   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3           10.104671   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3            9.767553   \n",
       "\n",
       "                                      pct_counts_in_top_20_genes  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                    16.935279   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                    26.054983   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                    39.777040   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                     9.971723   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                    23.027787   \n",
       "...                                                          ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                   15.043128   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                   18.732808   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                   11.249199   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3                   26.255316   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                   27.456035   \n",
       "\n",
       "                                      pct_counts_mt  pct_counts_ribo  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "...                                             ...              ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "\n",
       "                                      pct_counts_hb  doublet_score_scDbFinder  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0             0.0                  0.001438   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0             0.0                  0.004471   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0             0.0                  0.175868   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0             0.0                  0.001208   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0             0.0                  0.001120   \n",
       "...                                             ...                       ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3            0.0                  0.000336   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3            0.0                  0.001675   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3            0.0                  0.184157   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3            0.0                  0.064821   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3            0.0                  0.013941   \n",
       "\n",
       "                                     doublet_class_scDbFinder  doublet_dbd  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "...                                                       ...          ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                  singlet          1.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "\n",
       "                                      doublet_score_dbd  \n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0        9.467655e-15  \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0        4.596916e-13  \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0        8.579486e-03  \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0        2.458157e-06  \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0        3.945921e-19  \n",
       "...                                                 ...  \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3       3.440510e-11  \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3       7.328824e+01  \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3       1.199975e+00  \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3       1.128238e-06  \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3       8.697339e-01  \n",
       "\n",
       "[25300 rows x 16 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d81d49-6b2e-4351-9a7d-e701210f593b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce4891ee-aabe-4c3a-823b-99a7347ecc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('G:\\Data processing pipeline 0.1 Yohan\\scRNA\\Output\\cvs_prediction', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81e4605d-b88c-4aeb-97de-2a5ae1fc9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv ='G:\\Data processing pipeline 0.1 Yohan\\scRNA\\Output\\cvs_prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10093fe0-8f2d-4e3e-af01-e7b9113648f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(path_csv + '/PREDICTIONS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774af081-aca6-4260-866b-6f16c359007a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd6afdce-29ae-48dd-92a6-52317ad6e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('G:/Data processing pipeline 0.1 Yohan/scRNA/Output/adata_post_celltypist', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86d43a4b-bcb1-40df-acd5-97ee3053c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('G:/Data processing pipeline 0.1 Yohan/scRNA/Output/adata_post_celltypist', f'adata_concat_post_celltypist.h5ad')\n",
    "adata.write(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c82dc1-9add-4143-b776-ba10231852ac",
   "metadata": {},
   "source": [
    "# scVI label transfering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5eeba-370e-44d9-af24-3aabdcc5b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warning : restart kernel to free RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d67cf65-09b5-4ca5-9a2b-5e30ea490595",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('G:/Data processing pipeline 0.1 Yohan/scRNA/Output/adata_post_celltypist/adata_concat_post_celltypist.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4b58cf2-70cb-4408-97d0-81ed83016517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 25300 × 18087\n",
       "    obs: 'Sample', 'dpi', 'Id', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb', 'doublet_score_scDbFinder', 'doublet_class_scDbFinder', 'doublet_dbd', 'doublet_score_dbd'\n",
       "    var: 'gene_names', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de920b2-99eb-4870-a112-e3372f11df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = sc.read_h5ad('G:/Data processing pipeline 0.1 Yohan/scRNA/Gene ref data/query_raw_healthy_cells.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49db999e-6420-4aae-a4fe-1e4fb93d060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['cell_type'] = 'Unknown'\n",
    "adata.obs['Batch'] = 'Gaia_exp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d55c3bc-ce54-4576-98b0-79d46f517bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(query, min_cells = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfbe5f8b-ea4e-4f52-a350-14b0a77dd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.obs['Batch'] = 'query'\n",
    "query.obs['Id'] = query.obs.donor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f76c334-0408-473f-b731-2d60691ca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_subset = sc.pp.subsample(query, fraction = 0.25, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eb1d591-85d8-4cf0-8bde-672fc6d46b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_subset.obs['Batch'] = 'query'\n",
    "#query_subset.obs['Id'] = query_subset.obs.donor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d079754d-6598-43cd-8120-ad0fded25fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_names</th>\n",
       "      <th>feature_types</th>\n",
       "      <th>genome</th>\n",
       "      <th>mt</th>\n",
       "      <th>ribo</th>\n",
       "      <th>hb</th>\n",
       "      <th>n_cells_by_counts</th>\n",
       "      <th>mean_counts</th>\n",
       "      <th>log1p_mean_counts</th>\n",
       "      <th>pct_dropout_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000187634</th>\n",
       "      <td>SAMD11</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>99.940711</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000188976</th>\n",
       "      <td>NOC2L</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10296</td>\n",
       "      <td>0.594585</td>\n",
       "      <td>0.466614</td>\n",
       "      <td>59.304348</td>\n",
       "      <td>15043.0</td>\n",
       "      <td>9.618734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187961</th>\n",
       "      <td>KLHL17</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1725</td>\n",
       "      <td>0.073518</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>93.181818</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>7.528869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187583</th>\n",
       "      <td>PLEKHN1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3808</td>\n",
       "      <td>0.227510</td>\n",
       "      <td>0.204988</td>\n",
       "      <td>84.948617</td>\n",
       "      <td>5756.0</td>\n",
       "      <td>8.658172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187642</th>\n",
       "      <td>PERM1</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>157</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>99.379447</td>\n",
       "      <td>173.0</td>\n",
       "      <td>5.159055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFP</th>\n",
       "      <td>EGFP</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>190</td>\n",
       "      <td>0.040356</td>\n",
       "      <td>0.039563</td>\n",
       "      <td>99.249012</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>6.929517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REPLI</th>\n",
       "      <td>REPLI</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>317</td>\n",
       "      <td>0.068142</td>\n",
       "      <td>0.065921</td>\n",
       "      <td>98.747036</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>7.452982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLYCO</th>\n",
       "      <td>GLYCO</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>308</td>\n",
       "      <td>0.073834</td>\n",
       "      <td>0.071235</td>\n",
       "      <td>98.782609</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>7.533159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMB</th>\n",
       "      <td>MEMB</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>524</td>\n",
       "      <td>0.128103</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>97.928854</td>\n",
       "      <td>3241.0</td>\n",
       "      <td>8.083945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUCL</th>\n",
       "      <td>NUCL</td>\n",
       "      <td>Gene Expression</td>\n",
       "      <td>refdata-gex-GRCh38-2020-A_customprobe1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>524</td>\n",
       "      <td>0.154704</td>\n",
       "      <td>0.143844</td>\n",
       "      <td>97.928854</td>\n",
       "      <td>3914.0</td>\n",
       "      <td>8.272571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18087 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gene_names    feature_types  \\\n",
       "ENSG00000187634     SAMD11  Gene Expression   \n",
       "ENSG00000188976      NOC2L  Gene Expression   \n",
       "ENSG00000187961     KLHL17  Gene Expression   \n",
       "ENSG00000187583    PLEKHN1  Gene Expression   \n",
       "ENSG00000187642      PERM1  Gene Expression   \n",
       "...                    ...              ...   \n",
       "EGFP                  EGFP  Gene Expression   \n",
       "REPLI                REPLI  Gene Expression   \n",
       "GLYCO                GLYCO  Gene Expression   \n",
       "MEMB                  MEMB  Gene Expression   \n",
       "NUCL                  NUCL  Gene Expression   \n",
       "\n",
       "                                                 genome     mt   ribo     hb  \\\n",
       "ENSG00000187634  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000188976  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000187961  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000187583  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "ENSG00000187642  refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "...                                                 ...    ...    ...    ...   \n",
       "EGFP             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "REPLI            refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "GLYCO            refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "MEMB             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "NUCL             refdata-gex-GRCh38-2020-A_customprobe1  False  False  False   \n",
       "\n",
       "                 n_cells_by_counts  mean_counts  log1p_mean_counts  \\\n",
       "ENSG00000187634                 15     0.000593           0.000593   \n",
       "ENSG00000188976              10296     0.594585           0.466614   \n",
       "ENSG00000187961               1725     0.073518           0.070941   \n",
       "ENSG00000187583               3808     0.227510           0.204988   \n",
       "ENSG00000187642                157     0.006838           0.006815   \n",
       "...                            ...          ...                ...   \n",
       "EGFP                           190     0.040356           0.039563   \n",
       "REPLI                          317     0.068142           0.065921   \n",
       "GLYCO                          308     0.073834           0.071235   \n",
       "MEMB                           524     0.128103           0.120537   \n",
       "NUCL                           524     0.154704           0.143844   \n",
       "\n",
       "                 pct_dropout_by_counts  total_counts  log1p_total_counts  \n",
       "ENSG00000187634              99.940711          15.0            2.772589  \n",
       "ENSG00000188976              59.304348       15043.0            9.618734  \n",
       "ENSG00000187961              93.181818        1860.0            7.528869  \n",
       "ENSG00000187583              84.948617        5756.0            8.658172  \n",
       "ENSG00000187642              99.379447         173.0            5.159055  \n",
       "...                                ...           ...                 ...  \n",
       "EGFP                         99.249012        1021.0            6.929517  \n",
       "REPLI                        98.747036        1724.0            7.452982  \n",
       "GLYCO                        98.782609        1868.0            7.533159  \n",
       "MEMB                         97.928854        3241.0            8.083945  \n",
       "NUCL                         97.928854        3914.0            8.272571  \n",
       "\n",
       "[18087 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707f69d-d0df-48a5-b05d-bf9c8918239d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f173a-9af7-4a67-8646-2e7baf054000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc01ee-cbb1-40d4-96c0-ef5d6061b549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e267cd7d-fec9-4bf4-8a18-6b097a0bc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "dater = sc.concat((adata, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dbef157-acd8-4da6-acc0-e901154f5608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>log1p_n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "      <th>pct_counts_in_top_20_genes</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>pct_counts_ribo</th>\n",
       "      <th>pct_counts_hb</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>Batch</th>\n",
       "      <th>_scvi_batch</th>\n",
       "      <th>_scvi_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4997</td>\n",
       "      <td>4997</td>\n",
       "      <td>8.516793</td>\n",
       "      <td>15760.0</td>\n",
       "      <td>9.665294</td>\n",
       "      <td>16.935279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4357</td>\n",
       "      <td>4357</td>\n",
       "      <td>8.379769</td>\n",
       "      <td>14550.0</td>\n",
       "      <td>9.585415</td>\n",
       "      <td>26.054983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>6425</td>\n",
       "      <td>6425</td>\n",
       "      <td>8.768108</td>\n",
       "      <td>37675.0</td>\n",
       "      <td>10.536778</td>\n",
       "      <td>39.777040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4802</td>\n",
       "      <td>4802</td>\n",
       "      <td>8.476996</td>\n",
       "      <td>12024.0</td>\n",
       "      <td>9.394743</td>\n",
       "      <td>9.971723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4699</td>\n",
       "      <td>4699</td>\n",
       "      <td>8.455318</td>\n",
       "      <td>15655.0</td>\n",
       "      <td>9.658609</td>\n",
       "      <td>23.027787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3_4_GCTTGAACACGACGAA</th>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>1268</td>\n",
       "      <td>1268</td>\n",
       "      <td>7.145984</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>7.700748</td>\n",
       "      <td>19.873246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lung pericyte</td>\n",
       "      <td>query</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGTGGATCGTTCCTG_5-PX5-sub_mould</th>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>5559</td>\n",
       "      <td>5559</td>\n",
       "      <td>8.623353</td>\n",
       "      <td>37883.0</td>\n",
       "      <td>10.542284</td>\n",
       "      <td>25.589314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alveolar macrophage</td>\n",
       "      <td>query</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCAGGATCAAGACGTG_F02526</th>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>2800</td>\n",
       "      <td>2800</td>\n",
       "      <td>7.937732</td>\n",
       "      <td>7523.0</td>\n",
       "      <td>8.925853</td>\n",
       "      <td>14.382560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ciliated columnar cell of tracheobronchial tree</td>\n",
       "      <td>query</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl</th>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>1542</td>\n",
       "      <td>1542</td>\n",
       "      <td>7.341484</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>8.347590</td>\n",
       "      <td>25.171842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alveolar macrophage</td>\n",
       "      <td>query</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>022C-b_GGATGTTTCCAAGTAC_adams</th>\n",
       "      <td>homosapiens_None_2023_None_sikkemalisa_002_d10...</td>\n",
       "      <td>3077</td>\n",
       "      <td>3077</td>\n",
       "      <td>8.032035</td>\n",
       "      <td>10531.0</td>\n",
       "      <td>9.262174</td>\n",
       "      <td>23.074732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>query</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1328042 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            Id  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                                                     Inf_J3   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                                                     Inf_J3   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                                                     Inf_J3   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                                                     Inf_J3   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                                                     Inf_J3   \n",
       "...                                                                                        ...   \n",
       "P3_4_GCTTGAACACGACGAA                        homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould             homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "TCAGGATCAAGACGTG_F02526                      homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl  homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                homosapiens_None_2023_None_sikkemalisa_002_d10...   \n",
       "\n",
       "                                             n_genes  n_genes_by_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0             4997               4997   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0             4357               4357   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0             6425               6425   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0             4802               4802   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0             4699               4699   \n",
       "...                                              ...                ...   \n",
       "P3_4_GCTTGAACACGACGAA                           1268               1268   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                5559               5559   \n",
       "TCAGGATCAAGACGTG_F02526                         2800               2800   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl     1542               1542   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                   3077               3077   \n",
       "\n",
       "                                             log1p_n_genes_by_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                         8.516793   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                         8.379769   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                         8.768108   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                         8.476996   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                         8.455318   \n",
       "...                                                              ...   \n",
       "P3_4_GCTTGAACACGACGAA                                       7.145984   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                            8.623353   \n",
       "TCAGGATCAAGACGTG_F02526                                     7.937732   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                 7.341484   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                               8.032035   \n",
       "\n",
       "                                             total_counts  log1p_total_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0               15760.0            9.665294   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0               14550.0            9.585415   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0               37675.0           10.536778   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0               12024.0            9.394743   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0               15655.0            9.658609   \n",
       "...                                                   ...                 ...   \n",
       "P3_4_GCTTGAACACGACGAA                              2209.0            7.700748   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                  37883.0           10.542284   \n",
       "TCAGGATCAAGACGTG_F02526                            7523.0            8.925853   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl        4219.0            8.347590   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                     10531.0            9.262174   \n",
       "\n",
       "                                             pct_counts_in_top_20_genes  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                           16.935279   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                           26.054983   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                           39.777040   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                            9.971723   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                           23.027787   \n",
       "...                                                                 ...   \n",
       "P3_4_GCTTGAACACGACGAA                                         19.873246   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                              25.589314   \n",
       "TCAGGATCAAGACGTG_F02526                                       14.382560   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                   25.171842   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                                 23.074732   \n",
       "\n",
       "                                             pct_counts_mt  pct_counts_ribo  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                    0.0              0.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                    0.0              0.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                    0.0              0.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                    0.0              0.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                    0.0              0.0   \n",
       "...                                                    ...              ...   \n",
       "P3_4_GCTTGAACACGACGAA                                  0.0              0.0   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                       0.0              0.0   \n",
       "TCAGGATCAAGACGTG_F02526                                0.0              0.0   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl            0.0              0.0   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                          0.0              0.0   \n",
       "\n",
       "                                             pct_counts_hb  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                    0.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                    0.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                    0.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                    0.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                    0.0   \n",
       "...                                                    ...   \n",
       "P3_4_GCTTGAACACGACGAA                                  0.0   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                       0.0   \n",
       "TCAGGATCAAGACGTG_F02526                                0.0   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl            0.0   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                          0.0   \n",
       "\n",
       "                                                                                   cell_type  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                                                  Unknown   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                                                  Unknown   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                                                  Unknown   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                                                  Unknown   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                                                  Unknown   \n",
       "...                                                                                      ...   \n",
       "P3_4_GCTTGAACACGACGAA                                                          lung pericyte   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                                         alveolar macrophage   \n",
       "TCAGGATCAAGACGTG_F02526                      ciliated columnar cell of tracheobronchial tree   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl                              alveolar macrophage   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                                                        unknown   \n",
       "\n",
       "                                                Batch  _scvi_batch  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0          Gaia_exp            0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0          Gaia_exp            0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0          Gaia_exp            0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0          Gaia_exp            0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0          Gaia_exp            0   \n",
       "...                                               ...          ...   \n",
       "P3_4_GCTTGAACACGACGAA                           query            1   \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                query            1   \n",
       "TCAGGATCAAGACGTG_F02526                         query            1   \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl     query            1   \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                   query            1   \n",
       "\n",
       "                                             _scvi_labels  \n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                    51  \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                    51  \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                    51  \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                    51  \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                    51  \n",
       "...                                                   ...  \n",
       "P3_4_GCTTGAACACGACGAA                                  28  \n",
       "TTGTGGATCGTTCCTG_5-PX5-sub_mould                        8  \n",
       "TCAGGATCAAGACGTG_F02526                                14  \n",
       "CAACCTCTCATGTAGC-WSSS8015042-0_meyer_unpubl             8  \n",
       "022C-b_GGATGTTTCCAAGTAC_adams                          50  \n",
       "\n",
       "[1328042 rows x 14 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dater.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafa41e-3e51-48ee-bebb-6a2841e5a3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3208c015-2fae-488d-be00-1e6632af26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne fonctionne pas tant que pas les raws counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af5ce45-08b3-44d6-9cc6-a30b648b57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(dater, flavor = 'seurat_v3', n_top_genes=2000, batch_key=\"Batch\", subset = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "874334ca-ee59-4a0e-b0bd-45532268ccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1328042 × 2000\n",
       "    obs: 'Id', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb', 'cell_type', 'Batch', '_scvi_batch', '_scvi_labels'\n",
       "    var: 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n",
       "    uns: 'hvg', '_scvi_uuid', '_scvi_manager_uuid'\n",
       "    obsm: '_scvi_extra_categorical_covs'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f939fe1a-35fb-4f2d-aef0-c70cd9538a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to initialize backend 'cuda': \n",
      "Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "Unable to initialize backend 'tpu': UNIMPLEMENTED: LoadPjrtPlugin is not implemented on windows yet.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6: 100%|████████████████████| 6/6 [13:06<00:00, 130.70s/it, v_num=1, train_loss_step=391, train_loss_epoch=437]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=6` reached.\n",
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6: 100%|████████████████████| 6/6 [13:06<00:00, 131.09s/it, v_num=1, train_loss_step=391, train_loss_epoch=437]\n"
     ]
    }
   ],
   "source": [
    "scvi.model.SCVI.setup_anndata(dater, batch_key='Batch', categorical_covariate_keys = ['Id'])\n",
    "vae = scvi.model.SCVI(dater)\n",
    "vae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f4d78a-37d9-457e-91a5-7f76c380adfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vae.history[\"reconstruction_loss_train\"], label=\"Train Loss\")\n",
    "#plt.plot(vae.history[\"reconstruction_loss_validation\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "477b741e-a03c-468f-8bd3-23797e0d1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vae.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19b5c452-8acf-43ba-85a9-da3f0c0918ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Training for \u001b[1;36m25\u001b[0m epochs.                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████████| 25/25 [2:23:12<00:00, 343.97s/it, v_num=1, train_loss_step=426, train_loss_epoch=436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=25` reached.\n",
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████████| 25/25 [2:23:12<00:00, 343.68s/it, v_num=1, train_loss_step=426, train_loss_epoch=436]\n"
     ]
    }
   ],
   "source": [
    "lvae = scvi.model.SCANVI.from_scvi_model(vae, adata = dater, unlabeled_category = 'Unknown',\n",
    "                                        labels_key = 'cell_type')\n",
    "\n",
    "lvae.train(max_epochs=25, n_samples_per_label=400, train_size=0.7, check_val_every_n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c196843-b43e-44ac-9d3b-17d40a88c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_loss_step', 'validation_loss', 'elbo_validation', 'reconstruction_loss_validation', 'kl_local_validation', 'kl_global_validation', 'validation_classification_loss', 'validation_accuracy', 'validation_f1_score', 'validation_calibration_error', 'train_loss_epoch', 'elbo_train', 'reconstruction_loss_train', 'kl_local_train', 'kl_global_train', 'train_classification_loss', 'train_accuracy', 'train_f1_score', 'train_calibration_error'])\n"
     ]
    }
   ],
   "source": [
    "print(lvae.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47abe7a6-afcb-4c84-8831-26236fe49697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lvae.history[\"reconstruction_loss_train\"], label=\"Train Loss\")\n",
    "plt.plot(lvae.history[\"reconstruction_loss_validation\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f971c9-190d-4708-86e8-68f0faa6097c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0d9ad06-ff4a-4b62-97c6-9811d5f48def",
   "metadata": {},
   "outputs": [],
   "source": [
    "dater.obs['predicted'] = lvae.predict(dater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f89d53e-2643-427d-8e60-de0f1006dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dater.obs['transfer_score'] = lvae.predict(soft = True).max(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "462ca251-6c6f-4b33-9c23-87b005b8cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dater = dater[dater.obs.Batch == 'Gaia_exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a97cfcf8-91d6-4002-a5fa-9c042b549352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 25300 × 2000\n",
       "    obs: 'Id', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb', 'cell_type', 'Batch', '_scvi_batch', '_scvi_labels', 'predicted', 'transfer_score'\n",
       "    var: 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n",
       "    uns: 'hvg', '_scvi_uuid', '_scvi_manager_uuid'\n",
       "    obsm: '_scvi_extra_categorical_covs'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5689316e-bf99-437b-b4a8-9713987dda5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>transfer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>club cell</td>\n",
       "      <td>0.838011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>bronchial goblet cell</td>\n",
       "      <td>0.999624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>tracheobronchial goblet cell</td>\n",
       "      <td>0.984624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>nasal mucosa goblet cell</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>club cell</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>club cell</td>\n",
       "      <td>0.999576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>club cell</td>\n",
       "      <td>0.989853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>nasal mucosa goblet cell</td>\n",
       "      <td>0.996356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>epithelial cell of lower respiratory tract</td>\n",
       "      <td>0.998894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>club cell</td>\n",
       "      <td>0.681960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       predicted  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                                    club cell   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                        bronchial goblet cell   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                 tracheobronchial goblet cell   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                     nasal mucosa goblet cell   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                                    club cell   \n",
       "...                                                                          ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                                   club cell   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                                   club cell   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                    nasal mucosa goblet cell   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3  epithelial cell of lower respiratory tract   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                                   club cell   \n",
       "\n",
       "                                      transfer_score  \n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0         0.838011  \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0         0.999624  \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0         0.984624  \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0         0.981616  \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0         0.999853  \n",
       "...                                              ...  \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3        0.999576  \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3        0.989853  \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3        0.996356  \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3        0.998894  \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3        0.681960  \n",
       "\n",
       "[25300 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dater.obs[['predicted', 'transfer_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27ae9fe8-223d-4183-9765-ada4980125df",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.merge(right = dater.obs[['predicted', 'transfer_score']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "277a8813-9e21-4b7e-bbef-492b806f4b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>dpi</th>\n",
       "      <th>Id</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>log1p_n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "      <th>pct_counts_in_top_20_genes</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>pct_counts_ribo</th>\n",
       "      <th>pct_counts_hb</th>\n",
       "      <th>doublet_score_scDbFinder</th>\n",
       "      <th>doublet_class_scDbFinder</th>\n",
       "      <th>doublet_dbd</th>\n",
       "      <th>doublet_score_dbd</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>Batch</th>\n",
       "      <th>predicted</th>\n",
       "      <th>transfer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4997</td>\n",
       "      <td>4997</td>\n",
       "      <td>8.516793</td>\n",
       "      <td>15760.0</td>\n",
       "      <td>9.665294</td>\n",
       "      <td>16.935279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.467655e-15</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.838011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4357</td>\n",
       "      <td>4357</td>\n",
       "      <td>8.379769</td>\n",
       "      <td>14550.0</td>\n",
       "      <td>9.585415</td>\n",
       "      <td>26.054983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.596916e-13</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>bronchial goblet cell</td>\n",
       "      <td>0.999624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>6425</td>\n",
       "      <td>6425</td>\n",
       "      <td>8.768108</td>\n",
       "      <td>37675.0</td>\n",
       "      <td>10.536778</td>\n",
       "      <td>39.777040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175868</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.579486e-03</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>tracheobronchial goblet cell</td>\n",
       "      <td>0.984624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4802</td>\n",
       "      <td>4802</td>\n",
       "      <td>8.476996</td>\n",
       "      <td>12024.0</td>\n",
       "      <td>9.394743</td>\n",
       "      <td>9.971723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.458157e-06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>nasal mucosa goblet cell</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4699</td>\n",
       "      <td>4699</td>\n",
       "      <td>8.455318</td>\n",
       "      <td>15655.0</td>\n",
       "      <td>9.658609</td>\n",
       "      <td>23.027787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.945921e-19</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5428</td>\n",
       "      <td>5428</td>\n",
       "      <td>8.599510</td>\n",
       "      <td>17390.0</td>\n",
       "      <td>9.763708</td>\n",
       "      <td>15.043128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.440510e-11</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.999576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>6077</td>\n",
       "      <td>6077</td>\n",
       "      <td>8.712431</td>\n",
       "      <td>21812.0</td>\n",
       "      <td>9.990261</td>\n",
       "      <td>18.732808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>singlet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.328824e+01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.989853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5301</td>\n",
       "      <td>5301</td>\n",
       "      <td>8.575839</td>\n",
       "      <td>15610.0</td>\n",
       "      <td>9.655731</td>\n",
       "      <td>11.249199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184157</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.199975e+00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>nasal mucosa goblet cell</td>\n",
       "      <td>0.996356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5857</td>\n",
       "      <td>5857</td>\n",
       "      <td>8.675564</td>\n",
       "      <td>24456.0</td>\n",
       "      <td>10.104671</td>\n",
       "      <td>26.255316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064821</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.128238e-06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>epithelial cell of lower respiratory tract</td>\n",
       "      <td>0.998894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>4998</td>\n",
       "      <td>4998</td>\n",
       "      <td>8.516993</td>\n",
       "      <td>17457.0</td>\n",
       "      <td>9.767553</td>\n",
       "      <td>27.456035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>singlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.697339e-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.681960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25300 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Sample dpi       Id  n_genes  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4997   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4357   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     6425   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4802   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0     Inf  J3   Inf_J3     4699   \n",
       "...                                     ...  ..      ...      ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     5428   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     6077   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     5301   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     5857   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3   Mock  J6  Mock_J6     4998   \n",
       "\n",
       "                                      n_genes_by_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                4997   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                4357   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                6425   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                4802   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                4699   \n",
       "...                                                 ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3               5428   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3               6077   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3               5301   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3               5857   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3               4998   \n",
       "\n",
       "                                      log1p_n_genes_by_counts  total_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                  8.516793       15760.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                  8.379769       14550.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                  8.768108       37675.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                  8.476996       12024.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                  8.455318       15655.0   \n",
       "...                                                       ...           ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                 8.599510       17390.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                 8.712431       21812.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                 8.575839       15610.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3                 8.675564       24456.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                 8.516993       17457.0   \n",
       "\n",
       "                                      log1p_total_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0             9.665294   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0             9.585415   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0            10.536778   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0             9.394743   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0             9.658609   \n",
       "...                                                  ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3            9.763708   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3            9.990261   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3            9.655731   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3           10.104671   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3            9.767553   \n",
       "\n",
       "                                      pct_counts_in_top_20_genes  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                    16.935279   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                    26.054983   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                    39.777040   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                     9.971723   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                    23.027787   \n",
       "...                                                          ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                   15.043128   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                   18.732808   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                   11.249199   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3                   26.255316   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                   27.456035   \n",
       "\n",
       "                                      pct_counts_mt  pct_counts_ribo  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0             0.0              0.0   \n",
       "...                                             ...              ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3            0.0              0.0   \n",
       "\n",
       "                                      pct_counts_hb  doublet_score_scDbFinder  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0             0.0                  0.001438   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0             0.0                  0.004471   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0             0.0                  0.175868   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0             0.0                  0.001208   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0             0.0                  0.001120   \n",
       "...                                             ...                       ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3            0.0                  0.000336   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3            0.0                  0.001675   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3            0.0                  0.184157   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3            0.0                  0.064821   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3            0.0                  0.013941   \n",
       "\n",
       "                                     doublet_class_scDbFinder  doublet_dbd  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                   singlet          0.0   \n",
       "...                                                       ...          ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                  singlet          1.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                  singlet          0.0   \n",
       "\n",
       "                                      doublet_score_dbd cell_type     Batch  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0        9.467655e-15   Unknown  Gaia_exp   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0        4.596916e-13   Unknown  Gaia_exp   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0        8.579486e-03   Unknown  Gaia_exp   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0        2.458157e-06   Unknown  Gaia_exp   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0        3.945921e-19   Unknown  Gaia_exp   \n",
       "...                                                 ...       ...       ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3       3.440510e-11   Unknown  Gaia_exp   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3       7.328824e+01   Unknown  Gaia_exp   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3       1.199975e+00   Unknown  Gaia_exp   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3       1.128238e-06   Unknown  Gaia_exp   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3       8.697339e-01   Unknown  Gaia_exp   \n",
       "\n",
       "                                                                       predicted  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0                                    club cell   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0                        bronchial goblet cell   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0                 tracheobronchial goblet cell   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0                     nasal mucosa goblet cell   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0                                    club cell   \n",
       "...                                                                          ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3                                   club cell   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3                                   club cell   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3                    nasal mucosa goblet cell   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3  epithelial cell of lower respiratory tract   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3                                   club cell   \n",
       "\n",
       "                                      transfer_score  \n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3-0         0.838011  \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3-0         0.999624  \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3-0         0.984624  \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3-0         0.981616  \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3-0         0.999853  \n",
       "...                                              ...  \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6-3        0.999576  \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6-3        0.989853  \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6-3        0.996356  \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6-3        0.998894  \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6-3        0.681960  \n",
       "\n",
       "[25300 rows x 20 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b54a00c6-b112-43e9-b07d-5b212cf36020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_model_celltypist1_label</th>\n",
       "      <th>ref_model_celltypist1_score</th>\n",
       "      <th>ref_model_celltypist2_label</th>\n",
       "      <th>ref_model_celltypist2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.319114</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.951831</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.824988</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.357202</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.602141</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>AT2</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.987707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.080242</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.998898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.997562</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.996979</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.923008</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ref_model_celltypist1_label  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "...                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                         AT2   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "\n",
       "                                    ref_model_celltypist1_score  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                      0.319114   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                      0.951831   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                      0.824988   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                      0.357202   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                      0.602141   \n",
       "...                                                         ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                     0.055499   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                     0.080242   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                     0.997562   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                     0.996979   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                     0.923008   \n",
       "\n",
       "                                   ref_model_celltypist2_label  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "...                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "\n",
       "                                    ref_model_celltypist2_score  \n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                      0.999951  \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                      0.999886  \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                      0.999993  \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                      0.999483  \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                      0.999654  \n",
       "...                                                         ...  \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                     0.987707  \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                     0.998898  \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                     1.000000  \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                     0.999873  \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                     0.999691  \n",
       "\n",
       "[25300 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e5cd8b2-42d3-405d-98f3-c6e11fb732b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.index = adata.obs.index.str.replace(r'-\\d+$', '', regex=True)\n",
    "adata.obs_names = adata.obs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "336cff6b-fdb0-4ddb-af51-b2465ce57d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.merge(right = predictions, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4da7517a-136b-4a2d-bcca-4657fa885dc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>dpi</th>\n",
       "      <th>Id</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>log1p_n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>log1p_total_counts</th>\n",
       "      <th>pct_counts_in_top_20_genes</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>...</th>\n",
       "      <th>doublet_dbd</th>\n",
       "      <th>doublet_score_dbd</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>Batch</th>\n",
       "      <th>predicted</th>\n",
       "      <th>transfer_score</th>\n",
       "      <th>ref_model_celltypist1_label</th>\n",
       "      <th>ref_model_celltypist1_score</th>\n",
       "      <th>ref_model_celltypist2_label</th>\n",
       "      <th>ref_model_celltypist2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4997</td>\n",
       "      <td>4997</td>\n",
       "      <td>8.516793</td>\n",
       "      <td>15760.0</td>\n",
       "      <td>9.665294</td>\n",
       "      <td>16.935279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.467655e-15</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.838011</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.319114</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4357</td>\n",
       "      <td>4357</td>\n",
       "      <td>8.379769</td>\n",
       "      <td>14550.0</td>\n",
       "      <td>9.585415</td>\n",
       "      <td>26.054983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.596916e-13</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>bronchial goblet cell</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.951831</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>6425</td>\n",
       "      <td>6425</td>\n",
       "      <td>8.768108</td>\n",
       "      <td>37675.0</td>\n",
       "      <td>10.536778</td>\n",
       "      <td>39.777040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.579486e-03</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>tracheobronchial goblet cell</td>\n",
       "      <td>0.984624</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.824988</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4802</td>\n",
       "      <td>4802</td>\n",
       "      <td>8.476996</td>\n",
       "      <td>12024.0</td>\n",
       "      <td>9.394743</td>\n",
       "      <td>9.971723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.458157e-06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>nasal mucosa goblet cell</td>\n",
       "      <td>0.981616</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.357202</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3</th>\n",
       "      <td>Inf</td>\n",
       "      <td>J3</td>\n",
       "      <td>Inf_J3</td>\n",
       "      <td>4699</td>\n",
       "      <td>4699</td>\n",
       "      <td>8.455318</td>\n",
       "      <td>15655.0</td>\n",
       "      <td>9.658609</td>\n",
       "      <td>23.027787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.945921e-19</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.602141</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5428</td>\n",
       "      <td>5428</td>\n",
       "      <td>8.599510</td>\n",
       "      <td>17390.0</td>\n",
       "      <td>9.763708</td>\n",
       "      <td>15.043128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.440510e-11</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.999576</td>\n",
       "      <td>AT2</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.987707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>6077</td>\n",
       "      <td>6077</td>\n",
       "      <td>8.712431</td>\n",
       "      <td>21812.0</td>\n",
       "      <td>9.990261</td>\n",
       "      <td>18.732808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.328824e+01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.989853</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.080242</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.998898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5301</td>\n",
       "      <td>5301</td>\n",
       "      <td>8.575839</td>\n",
       "      <td>15610.0</td>\n",
       "      <td>9.655731</td>\n",
       "      <td>11.249199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.199975e+00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>nasal mucosa goblet cell</td>\n",
       "      <td>0.996356</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.997562</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>5857</td>\n",
       "      <td>5857</td>\n",
       "      <td>8.675564</td>\n",
       "      <td>24456.0</td>\n",
       "      <td>10.104671</td>\n",
       "      <td>26.255316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.128238e-06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>epithelial cell of lower respiratory tract</td>\n",
       "      <td>0.998894</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.996979</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6</th>\n",
       "      <td>Mock</td>\n",
       "      <td>J6</td>\n",
       "      <td>Mock_J6</td>\n",
       "      <td>4998</td>\n",
       "      <td>4998</td>\n",
       "      <td>8.516993</td>\n",
       "      <td>17457.0</td>\n",
       "      <td>9.767553</td>\n",
       "      <td>27.456035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.697339e-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gaia_exp</td>\n",
       "      <td>club cell</td>\n",
       "      <td>0.681960</td>\n",
       "      <td>Goblet (nasal)</td>\n",
       "      <td>0.923008</td>\n",
       "      <td>Secretory_Goblet</td>\n",
       "      <td>0.999691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25300 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Sample dpi       Id  n_genes  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3     Inf  J3   Inf_J3     4997   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3     Inf  J3   Inf_J3     4357   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3     Inf  J3   Inf_J3     6425   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3     Inf  J3   Inf_J3     4802   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3     Inf  J3   Inf_J3     4699   \n",
       "...                                   ...  ..      ...      ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6   Mock  J6  Mock_J6     5428   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6   Mock  J6  Mock_J6     6077   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6   Mock  J6  Mock_J6     5301   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6   Mock  J6  Mock_J6     5857   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6   Mock  J6  Mock_J6     4998   \n",
       "\n",
       "                                    n_genes_by_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                4997   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                4357   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                6425   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                4802   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                4699   \n",
       "...                                               ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6               5428   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6               6077   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6               5301   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6               5857   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6               4998   \n",
       "\n",
       "                                    log1p_n_genes_by_counts  total_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                  8.516793       15760.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                  8.379769       14550.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                  8.768108       37675.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                  8.476996       12024.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                  8.455318       15655.0   \n",
       "...                                                     ...           ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                 8.599510       17390.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                 8.712431       21812.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                 8.575839       15610.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                 8.675564       24456.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                 8.516993       17457.0   \n",
       "\n",
       "                                    log1p_total_counts  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3             9.665294   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3             9.585415   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3            10.536778   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3             9.394743   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3             9.658609   \n",
       "...                                                ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6            9.763708   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6            9.990261   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6            9.655731   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6           10.104671   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6            9.767553   \n",
       "\n",
       "                                    pct_counts_in_top_20_genes  pct_counts_mt  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                    16.935279            0.0   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                    26.054983            0.0   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                    39.777040            0.0   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                     9.971723            0.0   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                    23.027787            0.0   \n",
       "...                                                        ...            ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                   15.043128            0.0   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                   18.732808            0.0   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                   11.249199            0.0   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                   26.255316            0.0   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                   27.456035            0.0   \n",
       "\n",
       "                                    ...  doublet_dbd  doublet_score_dbd  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3   ...          0.0       9.467655e-15   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3   ...          0.0       4.596916e-13   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3   ...          0.0       8.579486e-03   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3   ...          0.0       2.458157e-06   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3   ...          0.0       3.945921e-19   \n",
       "...                                 ...          ...                ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6  ...          0.0       3.440510e-11   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6  ...          1.0       7.328824e+01   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6  ...          0.0       1.199975e+00   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6  ...          0.0       1.128238e-06   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6  ...          0.0       8.697339e-01   \n",
       "\n",
       "                                    cell_type     Batch  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3     Unknown  Gaia_exp   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3     Unknown  Gaia_exp   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3     Unknown  Gaia_exp   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3     Unknown  Gaia_exp   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3     Unknown  Gaia_exp   \n",
       "...                                       ...       ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6    Unknown  Gaia_exp   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6    Unknown  Gaia_exp   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6    Unknown  Gaia_exp   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6    Unknown  Gaia_exp   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6    Unknown  Gaia_exp   \n",
       "\n",
       "                                                                     predicted  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                                    club cell   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                        bronchial goblet cell   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                 tracheobronchial goblet cell   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                     nasal mucosa goblet cell   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                                    club cell   \n",
       "...                                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                                   club cell   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                                   club cell   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                    nasal mucosa goblet cell   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6  epithelial cell of lower respiratory tract   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                                   club cell   \n",
       "\n",
       "                                    transfer_score  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3         0.838011   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3         0.999624   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3         0.984624   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3         0.981616   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3         0.999853   \n",
       "...                                            ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6        0.999576   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6        0.989853   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6        0.996356   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6        0.998894   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6        0.681960   \n",
       "\n",
       "                                   ref_model_celltypist1_label  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3               Goblet (nasal)   \n",
       "...                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                         AT2   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6              Goblet (nasal)   \n",
       "\n",
       "                                   ref_model_celltypist1_score  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                     0.319114   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                     0.951831   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                     0.824988   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                     0.357202   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                     0.602141   \n",
       "...                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                    0.055499   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                    0.080242   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                    0.997562   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                    0.996979   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                    0.923008   \n",
       "\n",
       "                                   ref_model_celltypist2_label  \\\n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3             Secretory_Goblet   \n",
       "...                                                        ...   \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6            Secretory_Goblet   \n",
       "\n",
       "                                    ref_model_celltypist2_score  \n",
       "AAACAAGCAAGAACAAAGTAGGCT-1-Inf_J3                      0.999951  \n",
       "AAACAAGCACACTAAGAGTAGGCT-1-Inf_J3                      0.999886  \n",
       "AAACAAGCACCGTTTGAGTAGGCT-1-Inf_J3                      0.999993  \n",
       "AAACAAGCACTTCGATAGTAGGCT-1-Inf_J3                      0.999483  \n",
       "AAACAAGCATGGTCAAAGTAGGCT-1-Inf_J3                      0.999654  \n",
       "...                                                         ...  \n",
       "TTTGGACGTATCCGCAAACGGGAA-1-Mock_J6                     0.987707  \n",
       "TTTGGACGTCCTCACTAACGGGAA-1-Mock_J6                     0.998898  \n",
       "TTTGGACGTCCTTCTAAACGGGAA-1-Mock_J6                     1.000000  \n",
       "TTTGGACGTGTGATGAAACGGGAA-1-Mock_J6                     0.999873  \n",
       "TTTGGCGGTAACTACCAACGGGAA-1-Mock_J6                     0.999691  \n",
       "\n",
       "[25300 rows x 24 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "feea2595-c080-449b-ab12-37ba591e0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('G:/Data processing pipeline 0.1 Yohan/scRNA/Output/unintegrated_scvilabels', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5f1075-8730-4d0e-aff8-a833fd1938cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unintegrated_data = 'G:/Data processing pipeline 0.1 Yohan/scRNA/Output/unintegrated_scvilabels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0ba5402d-50c9-4def-ad6f-4a2ca0c2bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n",
      "... storing 'Batch' as categorical\n",
      "... storing 'predicted' as categorical\n",
      "... storing 'ref_model_celltypist1_label' as categorical\n",
      "... storing 'ref_model_celltypist2_label' as categorical\n"
     ]
    }
   ],
   "source": [
    "adata.write_h5ad(path_unintegrated_data +'/unintigrated.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60708636-f89a-44ee-80a0-1e68af5465ef",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17fff40e-78b1-4bd3-874b-1d275e9db65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.autotune import ModelTuner\n",
    "import tempfile\n",
    "\n",
    "import ray\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from ray import tune\n",
    "from scvi import autotune\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af825d10-1ab8-4986-95fc-c210ae57727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(path_unintegrated_data +'/unintigrated.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebe8f4d-165f-4ee0-880c-3f70e4e4ad52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 25300 × 18087\n",
       "    obs: 'Sample', 'dpi', 'Id', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb', 'doublet_score_scDbFinder', 'doublet_class_scDbFinder', 'doublet_dbd', 'doublet_score_dbd', 'cell_type', 'Batch', 'predicted', 'transfer_score', 'ref_model_celltypist1_label', 'ref_model_celltypist1_score', 'ref_model_celltypist2_label', 'ref_model_celltypist2_score'\n",
       "    var: 'gene_names', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eefd20-83b9-406d-8254-58b2a865cd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42051b23-4ec8-4eb0-ba39-76555355ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run with scvi-tools version: 1.1.6.post2\n"
     ]
    }
   ],
   "source": [
    "scvi.settings.seed = 0\n",
    "print(\"Last run with scvi-tools version:\", scvi.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedb6436-63a3-4ac5-800d-3fe5dc44d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(adata, min_cells = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decc01be-b27a-4812-8ac3-96114b0a1562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 25300 × 13893\n",
       "    obs: 'Sample', 'dpi', 'Id', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb', 'doublet_score_scDbFinder', 'doublet_class_scDbFinder', 'doublet_dbd', 'doublet_score_dbd', 'cell_type', 'Batch', 'predicted', 'transfer_score', 'ref_model_celltypist1_label', 'ref_model_celltypist1_score', 'ref_model_celltypist2_label', 'ref_model_celltypist2_score'\n",
       "    var: 'gene_names', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa34c15-22c3-41bc-a908-8e3cbc705696",
   "metadata": {},
   "source": [
    "### Selection of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7968fea7-e23a-4bcb-9f89-83c82f73db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = scvi.model.SCVI\n",
    "model_cls.setup_anndata(adata, categorical_covariate_keys = ['Id'],\n",
    "                             continuous_covariate_keys=['pct_counts_mt', 'pct_counts_ribo'])\n",
    "\n",
    "tuner = ModelTuner(model_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf84a61-61c0-49ae-8a81-6ce8e35822fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ModelTuner registry for SCVI\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ModelTuner registry for SCVI\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                  Tunable hyperparameters                  </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Hyperparameter      </span>┃<span style=\"font-weight: bold\"> Default value </span>┃<span style=\"font-weight: bold\">    Source    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">         n_hidden         </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      128      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">         n_latent         </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      10       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">         n_layers         </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">       1       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">       dropout_rate       </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      0.1      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">        dispersion        </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     gene      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">     log_variational      </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     True      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">     gene_likelihood      </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     zinb      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">   latent_distribution    </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">    normal     </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">    encode_covariates     </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     False     </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\"> deeply_inject_covariates </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     True      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">      use_batch_norm      </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     both      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">      use_layer_norm      </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     none      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">  use_observed_lib_size   </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     True      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">      var_activation      </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     None      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     VAE      </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">        optimizer         </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     Adam      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">            lr            </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     0.001     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">       weight_decay       </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     1e-06     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">           eps            </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     0.01      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">    n_steps_kl_warmup     </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     None      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">    n_epochs_kl_warmup    </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      400      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">   reduce_lr_on_plateau   </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     False     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">        lr_factor         </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      0.6      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">       lr_patience        </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      30       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">       lr_threshold       </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      0.0      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">          lr_min          </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">       0       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">      max_kl_weight       </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      1.0      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">      min_kl_weight       </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      0.0      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> TrainingPlan </span>│\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">        batch_size        </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">      128      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     SCVI     </span>│\n",
       "└──────────────────────────┴───────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                  Tunable hyperparameters                  \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Hyperparameter     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDefault value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Source   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m        n_hidden        \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     128     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m        n_latent        \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     10      \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m        n_layers        \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m      1      \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m      dropout_rate      \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     0.1     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m       dispersion       \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    gene     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m    log_variational     \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    True     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m    gene_likelihood     \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    zinb     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m  latent_distribution   \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m   normal    \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m   encode_covariates    \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    False    \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33mdeeply_inject_covariates\u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    True     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m     use_batch_norm     \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    both     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m     use_layer_norm     \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    none     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m use_observed_lib_size  \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    True     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m     var_activation     \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    None     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    VAE     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m       optimizer        \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    Adam     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m           lr           \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    0.001    \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m      weight_decay      \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    1e-06    \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m          eps           \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    0.01     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m   n_steps_kl_warmup    \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    None     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m   n_epochs_kl_warmup   \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     400     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m  reduce_lr_on_plateau  \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    False    \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m       lr_factor        \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     0.6     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m      lr_patience       \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     30      \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m      lr_threshold      \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     0.0     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m         lr_min         \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m      0      \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m     max_kl_weight      \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     1.0     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m     min_kl_weight      \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     0.0     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mTrainingPlan\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m       batch_size       \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m     128     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    SCVI    \u001b[0m\u001b[32m \u001b[0m│\n",
       "└──────────────────────────┴───────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">       Available metrics        </span>\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">     Metric      </span>┃<span style=\"font-weight: bold\">    Mode    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\"> validation_loss </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">    min     </span>│\n",
       "└─────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m       Available metrics        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m    Metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Mode   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33mvalidation_loss\u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m   min    \u001b[0m\u001b[38;5;128m \u001b[0m│\n",
       "└─────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Default search space                         </span>\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Hyperparameter </span>┃<span style=\"font-weight: bold\"> Sample function </span>┃<span style=\"font-weight: bold\">  Arguments  </span>┃<span style=\"font-weight: bold\"> Keyword arguments </span>┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #0087ff; text-decoration-color: #0087ff\">    n_hidden    </span>│<span style=\"color: #af00d7; text-decoration-color: #af00d7\">     choice      </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> [[64, 128]] </span>│<span style=\"color: #ff8700; text-decoration-color: #ff8700\">        {}         </span>│\n",
       "└────────────────┴─────────────────┴─────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Default search space                         \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mHyperparameter\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSample function\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Arguments \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mKeyword arguments\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[38;5;33m \u001b[0m\u001b[38;5;33m   n_hidden   \u001b[0m\u001b[38;5;33m \u001b[0m│\u001b[38;5;128m \u001b[0m\u001b[38;5;128m    choice     \u001b[0m\u001b[38;5;128m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m[[64, 128]]\u001b[0m\u001b[32m \u001b[0m│\u001b[38;5;208m \u001b[0m\u001b[38;5;208m       {}        \u001b[0m\u001b[38;5;208m \u001b[0m│\n",
       "└────────────────┴─────────────────┴─────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeddbbea-b1a4-4d23-91f1-ce300b54de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"n_hidden\": tune.choice([92, 128, 192, 256]),\n",
    "    \"n_latent\": tune.choice([10, 20, 30, 40, 50, 60]),\n",
    "    \"n_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"gene_likelihood\": tune.choice([\"nb\", \"zinb\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e790651-35ec-42d2-a667-ca329f96368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir = os.path.abspath(\"G:/ray_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9253dfb-1809-4e80-9ccd-404b8f761076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_dirname_creator(trial):\n",
    "    return f\"trial_{trial.trial_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3551bf81-1f33-4bf6-9140-267c11ceceed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-02-06 18:50:50</td></tr>\n",
       "<tr><td>Running for: </td><td>01:32:15.69        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.3/191.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=71<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: -11767.98095703125 | Iter 8.000: -11853.84033203125 | Iter 4.000: -12028.1494140625 | Iter 2.000: -12335.9111328125 | Iter 1.000: -12893.68359375<br>Logical resource usage: 0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  n_hidden</th><th style=\"text-align: right;\">  n_latent</th><th style=\"text-align: right;\">  n_layers</th><th style=\"text-align: right;\">         lr</th><th>gene_likelihood  </th><th style=\"text-align: right;\">  validation_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_trainable_32c9a2b6</td><td>TERMINATED</td><td>127.0.0.1:19980</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.000232751</td><td>zinb             </td><td style=\"text-align: right;\">          12485.3</td></tr>\n",
       "<tr><td>_trainable_7ab57f13</td><td>TERMINATED</td><td>127.0.0.1:15400</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000389874</td><td>zinb             </td><td style=\"text-align: right;\">          12038.1</td></tr>\n",
       "<tr><td>_trainable_6fae08bb</td><td>TERMINATED</td><td>127.0.0.1:21300</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000827677</td><td>nb               </td><td style=\"text-align: right;\">          11999.6</td></tr>\n",
       "<tr><td>_trainable_d2ecca54</td><td>TERMINATED</td><td>127.0.0.1:20288</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00379113 </td><td>nb               </td><td style=\"text-align: right;\">          11829.3</td></tr>\n",
       "<tr><td>_trainable_80a8ef66</td><td>TERMINATED</td><td>127.0.0.1:1960 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00219824 </td><td>nb               </td><td style=\"text-align: right;\">          11735.2</td></tr>\n",
       "<tr><td>_trainable_25238023</td><td>TERMINATED</td><td>127.0.0.1:15608</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.000211765</td><td>nb               </td><td style=\"text-align: right;\">          14587.2</td></tr>\n",
       "<tr><td>_trainable_d5ef8601</td><td>TERMINATED</td><td>127.0.0.1:2380 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00515586 </td><td>nb               </td><td style=\"text-align: right;\">          11805.5</td></tr>\n",
       "<tr><td>_trainable_098bbab0</td><td>TERMINATED</td><td>127.0.0.1:20212</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00340165 </td><td>nb               </td><td style=\"text-align: right;\">          11863.6</td></tr>\n",
       "<tr><td>_trainable_be87cd2d</td><td>TERMINATED</td><td>127.0.0.1:9492 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00961918 </td><td>zinb             </td><td style=\"text-align: right;\">          11738.2</td></tr>\n",
       "<tr><td>_trainable_abf04a0b</td><td>TERMINATED</td><td>127.0.0.1:2868 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00416042 </td><td>zinb             </td><td style=\"text-align: right;\">          11759.6</td></tr>\n",
       "<tr><td>_trainable_5fa59be2</td><td>TERMINATED</td><td>127.0.0.1:1976 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00245656 </td><td>zinb             </td><td style=\"text-align: right;\">          12497.7</td></tr>\n",
       "<tr><td>_trainable_e524f254</td><td>TERMINATED</td><td>127.0.0.1:15180</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00496073 </td><td>zinb             </td><td style=\"text-align: right;\">          11868.7</td></tr>\n",
       "<tr><td>_trainable_238da45a</td><td>TERMINATED</td><td>127.0.0.1:20456</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00221344 </td><td>zinb             </td><td style=\"text-align: right;\">          12583.7</td></tr>\n",
       "<tr><td>_trainable_21f59ae1</td><td>TERMINATED</td><td>127.0.0.1:20684</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.000136256</td><td>zinb             </td><td style=\"text-align: right;\">          17677.6</td></tr>\n",
       "<tr><td>_trainable_d745dc93</td><td>TERMINATED</td><td>127.0.0.1:13032</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.000117348</td><td>nb               </td><td style=\"text-align: right;\">          17886.3</td></tr>\n",
       "<tr><td>_trainable_4809b6b9</td><td>TERMINATED</td><td>127.0.0.1:7408 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000138946</td><td>zinb             </td><td style=\"text-align: right;\">          15756.9</td></tr>\n",
       "<tr><td>_trainable_37655536</td><td>TERMINATED</td><td>127.0.0.1:4680 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.000123086</td><td>zinb             </td><td style=\"text-align: right;\">          15944.4</td></tr>\n",
       "<tr><td>_trainable_47b7b241</td><td>TERMINATED</td><td>127.0.0.1:3604 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00639849 </td><td>nb               </td><td style=\"text-align: right;\">          11950.5</td></tr>\n",
       "<tr><td>_trainable_6e33de91</td><td>TERMINATED</td><td>127.0.0.1:9412 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000478973</td><td>nb               </td><td style=\"text-align: right;\">          13717.1</td></tr>\n",
       "<tr><td>_trainable_5e02901e</td><td>TERMINATED</td><td>127.0.0.1:10528</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000665216</td><td>nb               </td><td style=\"text-align: right;\">          13646.2</td></tr>\n",
       "<tr><td>_trainable_2f9d5cc4</td><td>TERMINATED</td><td>127.0.0.1:14232</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00992038 </td><td>zinb             </td><td style=\"text-align: right;\">          11818.4</td></tr>\n",
       "<tr><td>_trainable_57d4b03d</td><td>TERMINATED</td><td>127.0.0.1:19752</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00136616 </td><td>nb               </td><td style=\"text-align: right;\">          12613.6</td></tr>\n",
       "<tr><td>_trainable_6848f20f</td><td>TERMINATED</td><td>127.0.0.1:21460</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00944763 </td><td>zinb             </td><td style=\"text-align: right;\">          11861.8</td></tr>\n",
       "<tr><td>_trainable_6d1b19a0</td><td>TERMINATED</td><td>127.0.0.1:14352</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00131384 </td><td>nb               </td><td style=\"text-align: right;\">          13259.3</td></tr>\n",
       "<tr><td>_trainable_a4dde16c</td><td>TERMINATED</td><td>127.0.0.1:20188</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00813755 </td><td>zinb             </td><td style=\"text-align: right;\">          13453.9</td></tr>\n",
       "<tr><td>_trainable_2b5fd5e1</td><td>TERMINATED</td><td>127.0.0.1:6560 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00195598 </td><td>nb               </td><td style=\"text-align: right;\">          13287.1</td></tr>\n",
       "<tr><td>_trainable_940d316d</td><td>TERMINATED</td><td>127.0.0.1:21164</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00144393 </td><td>nb               </td><td style=\"text-align: right;\">          13333  </td></tr>\n",
       "<tr><td>_trainable_1385e2c0</td><td>TERMINATED</td><td>127.0.0.1:8932 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00717173 </td><td>zinb             </td><td style=\"text-align: right;\">          11755.5</td></tr>\n",
       "<tr><td>_trainable_396e6b43</td><td>TERMINATED</td><td>127.0.0.1:20200</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.0027547  </td><td>zinb             </td><td style=\"text-align: right;\">          11659  </td></tr>\n",
       "<tr><td>_trainable_3f8f8283</td><td>TERMINATED</td><td>127.0.0.1:20096</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000937271</td><td>nb               </td><td style=\"text-align: right;\">          12723.3</td></tr>\n",
       "<tr><td>_trainable_60f738d8</td><td>TERMINATED</td><td>127.0.0.1:13700</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00285802 </td><td>zinb             </td><td style=\"text-align: right;\">          12479.1</td></tr>\n",
       "<tr><td>_trainable_e2ce94f9</td><td>TERMINATED</td><td>127.0.0.1:10524</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00172983 </td><td>zinb             </td><td style=\"text-align: right;\">          12620.8</td></tr>\n",
       "<tr><td>_trainable_91f3fa2b</td><td>TERMINATED</td><td>127.0.0.1:8624 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000718176</td><td>nb               </td><td style=\"text-align: right;\">          13777.4</td></tr>\n",
       "<tr><td>_trainable_b856f348</td><td>TERMINATED</td><td>127.0.0.1:20328</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000416805</td><td>nb               </td><td style=\"text-align: right;\">          13952.5</td></tr>\n",
       "<tr><td>_trainable_f10b2633</td><td>TERMINATED</td><td>127.0.0.1:10192</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00109229 </td><td>zinb             </td><td style=\"text-align: right;\">          12653.2</td></tr>\n",
       "<tr><td>_trainable_08ddae52</td><td>TERMINATED</td><td>127.0.0.1:9244 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00297028 </td><td>nb               </td><td style=\"text-align: right;\">          12082.1</td></tr>\n",
       "<tr><td>_trainable_8f7bd807</td><td>TERMINATED</td><td>127.0.0.1:5124 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.000306714</td><td>nb               </td><td style=\"text-align: right;\">          15242  </td></tr>\n",
       "<tr><td>_trainable_a357ac3e</td><td>TERMINATED</td><td>127.0.0.1:14472</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00420488 </td><td>zinb             </td><td style=\"text-align: right;\">          11773.1</td></tr>\n",
       "<tr><td>_trainable_69ebf52b</td><td>TERMINATED</td><td>127.0.0.1:11092</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.000513979</td><td>nb               </td><td style=\"text-align: right;\">          13400.4</td></tr>\n",
       "<tr><td>_trainable_f630d4f9</td><td>TERMINATED</td><td>127.0.0.1:6252 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00609584 </td><td>zinb             </td><td style=\"text-align: right;\">          11822.4</td></tr>\n",
       "<tr><td>_trainable_c960aa43</td><td>TERMINATED</td><td>127.0.0.1:12912</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00339955 </td><td>nb               </td><td style=\"text-align: right;\">          11756  </td></tr>\n",
       "<tr><td>_trainable_23887728</td><td>TERMINATED</td><td>127.0.0.1:4404 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.0017271  </td><td>zinb             </td><td style=\"text-align: right;\">          12663.4</td></tr>\n",
       "<tr><td>_trainable_2668a299</td><td>TERMINATED</td><td>127.0.0.1:10664</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00239759 </td><td>zinb             </td><td style=\"text-align: right;\">          12533.4</td></tr>\n",
       "<tr><td>_trainable_ddcd0f0f</td><td>TERMINATED</td><td>127.0.0.1:11100</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.000180163</td><td>nb               </td><td style=\"text-align: right;\">          14644.2</td></tr>\n",
       "<tr><td>_trainable_6ef9be3d</td><td>TERMINATED</td><td>127.0.0.1:7492 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00479034 </td><td>zinb             </td><td style=\"text-align: right;\">          11797.2</td></tr>\n",
       "<tr><td>_trainable_fed3c1a3</td><td>TERMINATED</td><td>127.0.0.1:1988 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00109344 </td><td>nb               </td><td style=\"text-align: right;\">          13199.6</td></tr>\n",
       "<tr><td>_trainable_6e9658de</td><td>TERMINATED</td><td>127.0.0.1:11568</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00029528 </td><td>zinb             </td><td style=\"text-align: right;\">          14006.6</td></tr>\n",
       "<tr><td>_trainable_2c28a823</td><td>TERMINATED</td><td>127.0.0.1:2832 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.000633917</td><td>nb               </td><td style=\"text-align: right;\">          13630  </td></tr>\n",
       "<tr><td>_trainable_df8873d1</td><td>TERMINATED</td><td>127.0.0.1:9044 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00289173 </td><td>zinb             </td><td style=\"text-align: right;\">          12512.8</td></tr>\n",
       "<tr><td>_trainable_94a23c4a</td><td>TERMINATED</td><td>127.0.0.1:14880</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00377399 </td><td>nb               </td><td style=\"text-align: right;\">          12072.2</td></tr>\n",
       "<tr><td>_trainable_ede77fc2</td><td>TERMINATED</td><td>127.0.0.1:1968 </td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.000847713</td><td>zinb             </td><td style=\"text-align: right;\">          13502.6</td></tr>\n",
       "<tr><td>_trainable_a6a26ed6</td><td>TERMINATED</td><td>127.0.0.1:9200 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00516584 </td><td>nb               </td><td style=\"text-align: right;\">          11896.8</td></tr>\n",
       "<tr><td>_trainable_8b481d20</td><td>TERMINATED</td><td>127.0.0.1:15296</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00207195 </td><td>zinb             </td><td style=\"text-align: right;\">          12588.4</td></tr>\n",
       "<tr><td>_trainable_7891d8e6</td><td>TERMINATED</td><td>127.0.0.1:9784 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00164565 </td><td>nb               </td><td style=\"text-align: right;\">          12654.5</td></tr>\n",
       "<tr><td>_trainable_33b1859c</td><td>TERMINATED</td><td>127.0.0.1:5208 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00621804 </td><td>zinb             </td><td style=\"text-align: right;\">          11681.5</td></tr>\n",
       "<tr><td>_trainable_183fa2b3</td><td>TERMINATED</td><td>127.0.0.1:5536 </td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00126217 </td><td>nb               </td><td style=\"text-align: right;\">          13174.5</td></tr>\n",
       "<tr><td>_trainable_84d84d3a</td><td>TERMINATED</td><td>127.0.0.1:14360</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00830331 </td><td>zinb             </td><td style=\"text-align: right;\">          11714.3</td></tr>\n",
       "<tr><td>_trainable_9f13c075</td><td>TERMINATED</td><td>127.0.0.1:12076</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00600659 </td><td>zinb             </td><td style=\"text-align: right;\">          11728.3</td></tr>\n",
       "<tr><td>_trainable_3f4b521d</td><td>TERMINATED</td><td>127.0.0.1:20500</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00810832 </td><td>zinb             </td><td style=\"text-align: right;\">          11818.3</td></tr>\n",
       "<tr><td>_trainable_0465f97a</td><td>TERMINATED</td><td>127.0.0.1:9516 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00456471 </td><td>zinb             </td><td style=\"text-align: right;\">          12082.6</td></tr>\n",
       "<tr><td>_trainable_b12a0342</td><td>TERMINATED</td><td>127.0.0.1:9256 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00360701 </td><td>zinb             </td><td style=\"text-align: right;\">          12384.6</td></tr>\n",
       "<tr><td>_trainable_2aeb3c58</td><td>TERMINATED</td><td>127.0.0.1:20968</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00264277 </td><td>zinb             </td><td style=\"text-align: right;\">          13147.8</td></tr>\n",
       "<tr><td>_trainable_7c839dea</td><td>TERMINATED</td><td>127.0.0.1:4988 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00662213 </td><td>zinb             </td><td style=\"text-align: right;\">          11876.5</td></tr>\n",
       "<tr><td>_trainable_4200ec2a</td><td>TERMINATED</td><td>127.0.0.1:20316</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00997464 </td><td>zinb             </td><td style=\"text-align: right;\">          11792.2</td></tr>\n",
       "<tr><td>_trainable_7bf12892</td><td>TERMINATED</td><td>127.0.0.1:7184 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00562046 </td><td>zinb             </td><td style=\"text-align: right;\">          11781.8</td></tr>\n",
       "<tr><td>_trainable_ea964b46</td><td>TERMINATED</td><td>127.0.0.1:15608</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00893766 </td><td>zinb             </td><td style=\"text-align: right;\">          11740.5</td></tr>\n",
       "<tr><td>_trainable_22c434a4</td><td>TERMINATED</td><td>127.0.0.1:19800</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00731025 </td><td>zinb             </td><td style=\"text-align: right;\">          11710.4</td></tr>\n",
       "<tr><td>_trainable_bea962c9</td><td>TERMINATED</td><td>127.0.0.1:13324</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00815477 </td><td>zinb             </td><td style=\"text-align: right;\">          11706.9</td></tr>\n",
       "<tr><td>_trainable_41a70305</td><td>TERMINATED</td><td>127.0.0.1:20492</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.007298   </td><td>zinb             </td><td style=\"text-align: right;\">          12046.1</td></tr>\n",
       "<tr><td>_trainable_3a1cc40d</td><td>TERMINATED</td><td>127.0.0.1:8936 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00328058 </td><td>zinb             </td><td style=\"text-align: right;\">          12394.2</td></tr>\n",
       "<tr><td>_trainable_01ddb8e2</td><td>TERMINATED</td><td>127.0.0.1:10572</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00398916 </td><td>zinb             </td><td style=\"text-align: right;\">          11802.7</td></tr>\n",
       "<tr><td>_trainable_e2104fb6</td><td>TERMINATED</td><td>127.0.0.1:4736 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00531487 </td><td>zinb             </td><td style=\"text-align: right;\">          12085.3</td></tr>\n",
       "<tr><td>_trainable_e3d827bc</td><td>TERMINATED</td><td>127.0.0.1:1876 </td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.0023865  </td><td>zinb             </td><td style=\"text-align: right;\">          12944.2</td></tr>\n",
       "<tr><td>_trainable_fc453c20</td><td>TERMINATED</td><td>127.0.0.1:20044</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00435928 </td><td>zinb             </td><td style=\"text-align: right;\">          12419.9</td></tr>\n",
       "<tr><td>_trainable_1fde2e5a</td><td>TERMINATED</td><td>127.0.0.1:6228 </td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00191676 </td><td>zinb             </td><td style=\"text-align: right;\">          12945.3</td></tr>\n",
       "<tr><td>_trainable_99cc5cea</td><td>TERMINATED</td><td>127.0.0.1:14180</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00149704 </td><td>zinb             </td><td style=\"text-align: right;\">          13214.6</td></tr>\n",
       "<tr><td>_trainable_09f3d1b4</td><td>TERMINATED</td><td>127.0.0.1:11488</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00669222 </td><td>zinb             </td><td style=\"text-align: right;\">          11823.4</td></tr>\n",
       "<tr><td>_trainable_dda00448</td><td>TERMINATED</td><td>127.0.0.1:13792</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00326338 </td><td>zinb             </td><td style=\"text-align: right;\">          12357.6</td></tr>\n",
       "<tr><td>_trainable_d73fb21b</td><td>TERMINATED</td><td>127.0.0.1:20960</td><td style=\"text-align: right;\">        92</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00259722 </td><td>zinb             </td><td style=\"text-align: right;\">          13020.7</td></tr>\n",
       "<tr><td>_trainable_bef52f6b</td><td>TERMINATED</td><td>127.0.0.1:13212</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.0048277  </td><td>zinb             </td><td style=\"text-align: right;\">          11699.2</td></tr>\n",
       "<tr><td>_trainable_32e9f7dc</td><td>TERMINATED</td><td>127.0.0.1:2248 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        20</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00909427 </td><td>zinb             </td><td style=\"text-align: right;\">          11872.3</td></tr>\n",
       "<tr><td>_trainable_b1492aa2</td><td>TERMINATED</td><td>127.0.0.1:21096</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.0021648  </td><td>zinb             </td><td style=\"text-align: right;\">          12568.3</td></tr>\n",
       "<tr><td>_trainable_f4150e9f</td><td>TERMINATED</td><td>127.0.0.1:20700</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00110953 </td><td>zinb             </td><td style=\"text-align: right;\">          13223.4</td></tr>\n",
       "<tr><td>_trainable_ccc64d88</td><td>TERMINATED</td><td>127.0.0.1:20688</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00310645 </td><td>zinb             </td><td style=\"text-align: right;\">          12367.2</td></tr>\n",
       "<tr><td>_trainable_672b2952</td><td>TERMINATED</td><td>127.0.0.1:384  </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00570119 </td><td>zinb             </td><td style=\"text-align: right;\">          12377.2</td></tr>\n",
       "<tr><td>_trainable_6ef7024b</td><td>TERMINATED</td><td>127.0.0.1:9284 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00189149 </td><td>zinb             </td><td style=\"text-align: right;\">          13029.5</td></tr>\n",
       "<tr><td>_trainable_d78681fb</td><td>TERMINATED</td><td>127.0.0.1:7712 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.000102332</td><td>zinb             </td><td style=\"text-align: right;\">          15514  </td></tr>\n",
       "<tr><td>_trainable_2f704b0d</td><td>TERMINATED</td><td>127.0.0.1:12140</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00500932 </td><td>zinb             </td><td style=\"text-align: right;\">          11694.7</td></tr>\n",
       "<tr><td>_trainable_224ac9f1</td><td>TERMINATED</td><td>127.0.0.1:14364</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00374753 </td><td>zinb             </td><td style=\"text-align: right;\">          11703  </td></tr>\n",
       "<tr><td>_trainable_6571f4ef</td><td>TERMINATED</td><td>127.0.0.1:4960 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.000789   </td><td>zinb             </td><td style=\"text-align: right;\">          13146.7</td></tr>\n",
       "<tr><td>_trainable_0da55d78</td><td>TERMINATED</td><td>127.0.0.1:13032</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00152415 </td><td>zinb             </td><td style=\"text-align: right;\">          13442.9</td></tr>\n",
       "<tr><td>_trainable_b314e24e</td><td>TERMINATED</td><td>127.0.0.1:3148 </td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00281292 </td><td>zinb             </td><td style=\"text-align: right;\">          12361.2</td></tr>\n",
       "<tr><td>_trainable_e17037b6</td><td>TERMINATED</td><td>127.0.0.1:20500</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00122199 </td><td>zinb             </td><td style=\"text-align: right;\">          13131.2</td></tr>\n",
       "<tr><td>_trainable_9c5a5eca</td><td>TERMINATED</td><td>127.0.0.1:8892 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        50</td><td style=\"text-align: right;\">         3</td><td style=\"text-align: right;\">0.00056135 </td><td>zinb             </td><td style=\"text-align: right;\">          13414.3</td></tr>\n",
       "<tr><td>_trainable_541428c8</td><td>TERMINATED</td><td>127.0.0.1:11364</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        60</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.00409579 </td><td>zinb             </td><td style=\"text-align: right;\">          12032.1</td></tr>\n",
       "<tr><td>_trainable_55eb4a5d</td><td>TERMINATED</td><td>127.0.0.1:11404</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">        40</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.000177594</td><td>zinb             </td><td style=\"text-align: right;\">          14773.4</td></tr>\n",
       "<tr><td>_trainable_9aedc0fc</td><td>TERMINATED</td><td>127.0.0.1:12608</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00990309 </td><td>zinb             </td><td style=\"text-align: right;\">          11674.8</td></tr>\n",
       "<tr><td>_trainable_73a802b2</td><td>TERMINATED</td><td>127.0.0.1:11488</td><td style=\"text-align: right;\">       192</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00523998 </td><td>nb               </td><td style=\"text-align: right;\">          12119.9</td></tr>\n",
       "<tr><td>_trainable_7618e509</td><td>TERMINATED</td><td>127.0.0.1:1016 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.00975753 </td><td>zinb             </td><td style=\"text-align: right;\">          11717.9</td></tr>\n",
       "<tr><td>_trainable_19c5d03e</td><td>TERMINATED</td><td>127.0.0.1:4620 </td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">        30</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">0.000349048</td><td>zinb             </td><td style=\"text-align: right;\">          13623.9</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 17:18:28,724\tINFO worker.py:1821 -- Started a local Ray instance.\n",
      "2025-02-06 17:18:34,411\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2025-02-06 17:18:34,411\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=19980)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15400)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21300)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20288)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1960)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2380)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20212)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9492)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2868)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=1976)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=1976)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=1976)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=1976)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=1976)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=1976)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1976)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15180)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=15180)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=15180)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=15180)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=15180)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=15180)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15180)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20456)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20456)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20456)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20456)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20456)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20456)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20456)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20684)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20684)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20684)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20684)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20684)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20684)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20684)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7408)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=7408)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=7408)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=7408)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=7408)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=7408)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7408)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4680)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=4680)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=4680)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=4680)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=4680)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=4680)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4680)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=3604)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=3604)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=3604)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=3604)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=3604)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=3604)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=3604)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9412)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9412)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9412)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9412)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9412)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9412)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9412)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10528)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=10528)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=10528)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=10528)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=10528)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=10528)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10528)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14232)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=19752)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=19752)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=19752)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=19752)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=19752)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=19752)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=19752)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21460)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=21460)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=21460)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=21460)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=21460)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=21460)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21460)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14352)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=14352)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=14352)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=14352)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=14352)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=14352)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14352)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20188)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20188)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20188)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20188)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20188)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20188)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20188)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=6560)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=6560)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=6560)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=6560)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=6560)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=6560)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=6560)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21164)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=21164)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=21164)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=21164)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=21164)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=21164)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21164)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8932)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20200)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=20096)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20096)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20096)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20096)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20096)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20096)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20096)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13700)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=13700)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=13700)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=13700)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=13700)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=13700)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13700)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10524)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=10524)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=10524)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=10524)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=10524)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=10524)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10524)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8624)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=8624)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=8624)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=8624)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=8624)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=8624)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8624)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20328)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20328)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20328)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20328)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20328)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20328)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20328)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10192)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=10192)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=10192)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=10192)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=10192)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=10192)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10192)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9244)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9244)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9244)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9244)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9244)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9244)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9244)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=5124)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=5124)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=5124)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=5124)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=5124)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=5124)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=5124)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14472)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=11092)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=11092)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=11092)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=11092)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=11092)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=11092)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11092)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=6252)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12912)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=4404)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=4404)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=4404)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=4404)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=4404)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=4404)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4404)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10664)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=10664)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=10664)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=10664)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=10664)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=10664)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10664)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11100)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=11100)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=11100)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=11100)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=11100)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=11100)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11100)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7492)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=1988)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=1988)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=1988)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=1988)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=1988)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=1988)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1988)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11568)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=11568)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=11568)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=11568)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=11568)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=11568)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11568)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2832)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=2832)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=2832)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=2832)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=2832)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=2832)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2832)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9044)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9044)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9044)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9044)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9044)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9044)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9044)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14880)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=14880)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=14880)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=14880)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=14880)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=14880)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14880)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1968)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=1968)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=1968)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=1968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=1968)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=1968)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1968)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9200)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9200)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9200)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9200)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9200)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9200)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9200)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15296)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=15296)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=15296)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=15296)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=15296)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=15296)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15296)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9784)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9784)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9784)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9784)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9784)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9784)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9784)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=5208)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=5536)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=5536)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=5536)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=5536)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=5536)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=5536)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=5536)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14360)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12076)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9516)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9516)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9516)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9516)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9516)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9516)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9516)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9256)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9256)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9256)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9256)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9256)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9256)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9256)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20968)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20968)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20968)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20968)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20968)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20968)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4988)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=4988)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=4988)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=4988)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=4988)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=4988)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4988)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20316)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7184)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=15608)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=19800)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13324)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=20492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20492)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20492)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20492)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20492)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20492)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8936)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=8936)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=8936)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=8936)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=8936)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=8936)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8936)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10572)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=10572)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=10572)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=10572)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=10572)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=10572)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=10572)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4736)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=4736)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=4736)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=4736)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=4736)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=4736)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4736)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1876)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=1876)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=1876)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=1876)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=1876)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=1876)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1876)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20044)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20044)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20044)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20044)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20044)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20044)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20044)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=6228)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=6228)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=6228)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=6228)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=6228)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=6228)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=6228)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14180)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=14180)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=14180)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=14180)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=14180)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=14180)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14180)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13792)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=13792)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=13792)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=13792)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=13792)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=13792)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13792)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20960)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20960)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20960)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13212)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=2248)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=2248)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=2248)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=2248)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=2248)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=2248)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=2248)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21096)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=21096)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=21096)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=21096)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=21096)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=21096)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=21096)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20700)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20700)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20700)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20700)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20700)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20700)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20700)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20688)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20688)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20688)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20688)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20688)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20688)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20688)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=384)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=384)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=384)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=384)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=384)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=384)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=384)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9284)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=9284)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=9284)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=9284)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=9284)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=9284)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=9284)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7712)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=7712)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=7712)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=7712)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=7712)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=7712)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=7712)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12140)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=14364)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=4960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=4960)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=4960)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=4960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=4960)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=4960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4960)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=13032)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=3148)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=3148)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=3148)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=3148)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=3148)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=3148)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=3148)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=20500)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8892)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=8892)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=8892)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=8892)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=8892)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=8892)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=8892)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11364)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=11364)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=11364)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=11364)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=11364)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=11364)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11364)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11404)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=11404)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=11404)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=11404)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=11404)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=11404)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11404)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=12608)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=11488)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "2025-02-06 18:48:44,975\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\test\\AppData\\Local\\Temp\\ray\\session_2025-02-06_17-18-23_177034_11888\\artifacts\\2025-02-06_17-18-34\\2025-02-06_17-18-21_scvi\\driver_artifacts\\_trainable_19c5d03e_100_gene_likelihood=zinb,lr=0.0003,n_hidden=256,n_latent=30,n_layers=2_2025-02-06_18-48-44\n",
      "2025-02-06 18:48:44,975\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\test\\AppData\\Local\\Temp\\ray\\session_2025-02-06_17-18-23_177034_11888\\artifacts\\2025-02-06_17-18-34\\2025-02-06_17-18-21_scvi\\driver_artifacts\\_trainable_19c5d03e_100_gene_likelihood=zinb,lr=0.0003,n_hidden=256,n_latent=30,n_layers=2_2025-02-06_18-48-44\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=1016)\u001b[0m `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "2025-02-06 18:50:41,810\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\test\\AppData\\Local\\Temp\\ray\\session_2025-02-06_17-18-23_177034_11888\\artifacts\\2025-02-06_17-18-34\\2025-02-06_17-18-21_scvi\\driver_artifacts\\_trainable_19c5d03e_100_gene_likelihood=zinb,lr=0.0003,n_hidden=256,n_latent=30,n_layers=2_2025-02-06_18-48-44\n",
      "2025-02-06 18:50:41,826\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\test\\AppData\\Local\\Temp\\ray\\session_2025-02-06_17-18-23_177034_11888\\artifacts\\2025-02-06_17-18-34\\2025-02-06_17-18-21_scvi\\driver_artifacts\\_trainable_19c5d03e_100_gene_likelihood=zinb,lr=0.0003,n_hidden=256,n_latent=30,n_layers=2_2025-02-06_18-48-44\n",
      "\u001b[36m(_trainable pid=4620)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_trainable pid=4620)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_trainable pid=4620)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_trainable pid=4620)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_trainable pid=4620)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_trainable pid=4620)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(_trainable pid=4620)\u001b[0m C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "2025-02-06 18:50:49,999\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\test\\AppData\\Local\\Temp\\ray\\session_2025-02-06_17-18-23_177034_11888\\artifacts\\2025-02-06_17-18-34\\2025-02-06_17-18-21_scvi\\driver_artifacts\\_trainable_19c5d03e_100_gene_likelihood=zinb,lr=0.0003,n_hidden=256,n_latent=30,n_layers=2_2025-02-06_18-48-44\n",
      "2025-02-06 18:50:50,171\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'G:/ray_logs/2025-02-06_17-18-21_scvi' in 0.1562s.\n",
      "2025-02-06 18:50:50,202\tINFO tune.py:1041 -- Total run time: 5535.79 seconds (5535.53 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit(adata, metric=\"validation_loss\",\n",
    "                    resources = {'gpu': 1}, #have to specify gpu or might not use\n",
    "                    search_space = search_space,\n",
    "                   num_samples = 100,\n",
    "                   max_epochs = 20,\n",
    "                    logging_dir = logging_dir\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e579c-a8e1-4189-8588-a131c33078b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vl = 10000\n",
    "best_i = 0\n",
    "for i, res in enumerate(results.results):\n",
    "    vl = res.metrics['validation_loss']\n",
    "\n",
    "    if vl < best_vl:\n",
    "        best_vl = vl\n",
    "        best_i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d4566-cddd-4c3d-93c0-1dcc1160ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.results[best_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890643e4-4439-420b-a916-d9b490ff5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the metrics from results and use them for integration parameters ( ==> n_hidden = 92, n_latent = 60, n_layers = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7051f59-5384-4acd-892e-4ef399ec1ff9",
   "metadata": {},
   "source": [
    "### Run the integration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c305d14-ab76-4086-93f7-972af8cf0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.SCVI.setup_anndata(adata,\n",
    "                              categorical_covariate_keys = ['Id'],\n",
    "                             continuous_covariate_keys=['pct_counts_mt', 'pct_counts_ribo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970e0747-c81e-4cbf-94a3-95fb6f224968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scvi.model.SCVI(adata, n_hidden = 92, n_latent = 60, n_layers = 3, gene_likelihood = 'zinb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61093aae-3204-4496-b93b-c4867c484f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'lr': 0.0026}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c1f3f4-52bc-4feb-86f9-fc71608a1004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████| 200/200 [15:48<00:00,  4.69s/it, v_num=1, train_loss_step=1.2e+4, train_loss_epoch=1.17e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████| 200/200 [15:48<00:00,  4.74s/it, v_num=1, train_loss_step=1.2e+4, train_loss_epoch=1.17e+4]\n"
     ]
    }
   ],
   "source": [
    "model.train(max_epochs = 200, early_stopping = True, plan_kwargs = kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e642bd-ce48-4fd7-a32a-feb0ae0f83f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a557919-cdf8-4d21-a050-6442cfaf2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('G:/Data processing pipeline 0.1 Yohan/scRNA/Output/the_model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd88706-1a7d-434e-accc-04542798b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_model_integ = 'G:/Data processing pipeline 0.1 Yohan/scRNA/Output/the_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91fe5ba9-b9af-4d49-9c09-39193ae50c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path_folder_model_integ + '/the_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671ded9-0034-4292-b305-39c5986b9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restart kernel to free RAM if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f0b810a-bb42-4ef1-b1ec-c33691bf9f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File G:\u001b[35m/\u001b[0m\u001b[95mData\u001b[0m processing pipeline \u001b[1;36m0.1\u001b[0m Yohan/scRNA/Output/the_model/the_model\\model.pt already downloaded   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\anaconda3\\envs\\annot\\lib\\site-packages\\scvi\\model\\base\\_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "model = scvi.model.SCVI.load(path_folder_model_integ + '/the_model', adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e9490-1218-4b51-af90-a7cf11b1927c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb6f9345-be1d-48a0-81a6-fe0a51a06fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.history['reconstruction_loss_validation']['reconstruction_loss_validation'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a2e3e92-00c6-43a9-b047-4014da545dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history['reconstruction_loss_train']['reconstruction_loss_train'], label='train Loss')\n",
    "plt.plot(model.history['reconstruction_loss_validation']['reconstruction_loss_validation'], label='validation Loss')\n",
    "\n",
    "plt.axhline(y, c = 'k')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfe89088-dacf-4516-b1d6-c3878f613b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('G:/Data processing pipeline 0.1 Yohan/scRNA/Output/integrated_data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cab52bc4-b12c-43c8-9a99-a93fe1d1f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_integrated = 'G:/Data processing pipeline 0.1 Yohan/scRNA/Output/integrated_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae96d111-a3ab-4208-95d6-24eea52b357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad('G:/Data processing pipeline 0.1 Yohan/scRNA/Output/integrated_data' +'/'+ 'integrated_data.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fea22e2e-19e4-44cc-9a88-c0b7122c81e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 25300 × 13893\n",
       "    obs: 'Sample', 'dpi', 'Id', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb', 'doublet_score_scDbFinder', 'doublet_class_scDbFinder', 'doublet_dbd', 'doublet_score_dbd', 'cell_type', 'Batch', 'predicted', 'transfer_score', 'ref_model_celltypist1_label', 'ref_model_celltypist1_score', 'ref_model_celltypist2_label', 'ref_model_celltypist2_score', '_scvi_batch', '_scvi_labels'\n",
       "    var: 'gene_names', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells'\n",
       "    uns: '_scvi_uuid', '_scvi_manager_uuid'\n",
       "    obsm: '_scvi_extra_categorical_covs', '_scvi_extra_continuous_covs'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1454aea-69c2-4b60-97aa-f700049cf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Finishhhhhhheeeedddd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
